{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e26dd61",
   "metadata": {},
   "source": [
    "### 1. Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58819d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/27 07:49:55 WARN Utils: Your hostname, soaz resolves to a loopback address: 127.0.1.1; using 192.168.1.18 instead (on interface wlp0s20f3)\n",
      "25/10/27 07:49:55 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/27 07:49:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, RandomForestRegressor\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import countDistinct\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import when, col\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from xgboost.spark import SparkXGBRegressor\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"RegressionModels\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e3d3c1",
   "metadata": {},
   "source": [
    "### 2. Đọc dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03c8a73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu ban đầu:\n",
      "+--------+---------------------+------------+------+---+----+----+------+\n",
      "|image_id|street               |citi        |n_citi|bed|bath|sqft|price |\n",
      "+--------+---------------------+------------+------+---+----+----+------+\n",
      "|1       |124 C Street W       |Brawley, CA |48    |3  |2   |713 |228500|\n",
      "|2       |2304 Clark Road      |Imperial, CA|152   |3  |1   |800 |273950|\n",
      "|3       |755 Brawley Avenue   |Brawley, CA |48    |3  |1   |1082|350000|\n",
      "|4       |2207 R Carrillo Court|Calexico, CA|55    |4  |3   |2547|385100|\n",
      "|6       |1100 CAMILIA Street  |Calexico, CA|55    |4  |3   |2769|415000|\n",
      "+--------+---------------------+------------+------+---+----+----+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- image_id: integer (nullable = true)\n",
      " |-- street: string (nullable = true)\n",
      " |-- citi: string (nullable = true)\n",
      " |-- n_citi: integer (nullable = true)\n",
      " |-- bed: integer (nullable = true)\n",
      " |-- bath: integer (nullable = true)\n",
      " |-- sqft: integer (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = spark.read.csv('../../data/cleaned_data/data.csv', inferSchema= True, header= True)\n",
    "\n",
    "print(\"Dữ liệu ban đầu:\")\n",
    "df.show(5, truncate=False)\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23db8a22",
   "metadata": {},
   "source": [
    "### 3. Tiền xử lý dữ liệu và chuẩn bị features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6f1b9e",
   "metadata": {},
   "source": [
    "#### Xử lý cột street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a614c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.withColumn(\"street\", regexp_replace(\"street\", \"^[^ ]+ \", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b1c7f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|            street|count|\n",
      "+------------------+-----+\n",
      "|      not provided|   19|\n",
      "|      Calle Aragon|   15|\n",
      "|   Avenida Majorca|   14|\n",
      "|   Avenida Sevilla|   10|\n",
      "|    Woodland Drive|   10|\n",
      "|     Walnut Street|    8|\n",
      "|        9th Street|    8|\n",
      "|Country Club Drive|    8|\n",
      "|   Del Monte Drive|    8|\n",
      "|  Avenida Castilla|    8|\n",
      "| W San Marcos Blvd|    8|\n",
      "|     Acacia Avenue|    7|\n",
      "|   N Euclid Avenue|    7|\n",
      "|       Renault Way|    7|\n",
      "|    Palomar Avenue|    7|\n",
      "|        4th Street|    7|\n",
      "|   El Dorado Drive|    7|\n",
      "|       Park Avenue|    7|\n",
      "|   Magnolia Avenue|    6|\n",
      "|        Ash Street|    6|\n",
      "+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"street\").count().orderBy(col(\"count\").desc()).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50d5d7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|count(DISTINCT street)|\n",
      "+----------------------+\n",
      "|                 10378|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.select(countDistinct(\"street\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bda499e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "street_freq = df.groupBy(\"street\").count().withColumnRenamed(\"count\", \"street_frequency\")\n",
    "\n",
    "df = df.join(street_freq, on=\"street\", how=\"left\")\n",
    "\n",
    "df = df.withColumn(\"street\", col(\"street_frequency\")).drop(\"street_frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485c586e",
   "metadata": {},
   "source": [
    "#### Xử lý cột citi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcc0005b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                citi|count|\n",
      "+--------------------+-----+\n",
      "|       San Diego, CA|  579|\n",
      "|     Los Angeles, CA|  307|\n",
      "|       Lancaster, CA|  270|\n",
      "|       La Quinta, CA|  227|\n",
      "|       Riverside, CA|  221|\n",
      "|          Corona, CA|  208|\n",
      "|       Escondido, CA|  198|\n",
      "|        Palmdale, CA|  195|\n",
      "|         Fontana, CA|  182|\n",
      "|        Big Bear, CA|  175|\n",
      "|    Palm Springs, CA|  172|\n",
      "|Rancho Cucamonga, CA|  164|\n",
      "|       Oceanside, CA|  161|\n",
      "|        Murrieta, CA|  148|\n",
      "|     Palm Desert, CA|  145|\n",
      "|     Paso Robles, CA|  141|\n",
      "|  San Bernardino, CA|  138|\n",
      "|  Lake Arrowhead, CA|  137|\n",
      "|   Rancho Mirage, CA|  133|\n",
      "|        Temecula, CA|  132|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"citi\").count().orderBy(col(\"count\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bf59557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|count(DISTINCT citi)|\n",
      "+--------------------+\n",
      "|                 415|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(countDistinct(\"citi\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9fe02c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def spark_get_dummies(df: DataFrame, column: str) -> DataFrame:\n",
    "    unique_values = [row[0] for row in df.select(column).distinct().collect()]\n",
    "    for val in unique_values:\n",
    "        df = df.withColumn(f\"{column}_{val}\", when(col(column) == val, 1).otherwise(0))\n",
    "    return df.drop(column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1d69699",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark_get_dummies(df, \"citi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3add8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [c for c in df.columns if c != \"price\"] + [\"price\"]\n",
    "df = df.select(*cols)  \n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50a78d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/27 07:50:29 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+---+----+----+---------------+---------------+----------------+----------------+----------------------+------------------------+--------------+---------------------+--------------------+-----------------+---------------------+-----------------+---------------------+--------------------+------------------+-----------------------+-------------------+------------------------+-------------------+------------------+---------------------+------------------------+----------------+---------------+----------------+-------------------+-------------------+--------------------+------------------------+-------------------+--------------+----------------+------------------+---------------------+-------------------+-----------------+------------------+-----------------+----------------+--------------------+---------------+-----------------+----------------------+-------------------+---------------------+-------------------------+----------------+-----------------------------+--------------------+--------------------+--------------------+--------------------+------------------+-------------------+------------------+----------------+------------------+------------------+------------------------+------------------+--------------------+----------------------+---------------------+---------------+---------------------+---------------+-------------------------+-------------+-------------------+----------------------+----------------------+---------------+------------------+----------------------+-----------------------+--------------------+-----------------+-----------------+----------------+------------------+---------------------+-------------------+--------------------+--------------------+-----------------+---------------+------------------------+--------------+----------------+-------------------+-----------------+------------------+----------------+----------------+--------------------+---------------------+------------------------+----------------------+----------------+-----------------+--------------+----------------------+----------------------+------------------------+----------------+---------------------+------------------------+----------------------+-----------------------+----------------------+----------------+--------------------+----------------------+------------------+-------------------+-------------------------+--------------+---------------------+--------------------+--------------+------------------+-----------------+---------------+-----------------+-------------------------+--------------+----------------------+---------------+-----------------------+-----------------------+-----------------+------------------------+---------------+-----------------------+------------------------+--------------------+----------------------+-------------------+-------------------+---------------------+---------------------+----------------+---------------------+---------------------+---------------------+----------------+-----------------+-------------------+---------------+--------------------+--------------------+---------------+-----------------+--------------+--------------+-----------------+----------------+------------------+----------------------+------------------+--------------------+-------------------------+--------------------+---------------+-----------------+-----------------+----------------+---------------+----------------+-----------------+-----------------+--------------------+-----------------+--------------------+--------------+----------------------+-----------------+------------------------+-------------------------+----------------------+------------------+-------------------+--------------------+-------------------+----------------+------------------+-----------------------+---------------------+-----------------+---------------------+---------------------+-------------------------------+-------------------+---------------------+---------------+----------------------+----------------------+-----------------------+---------------------+-----------------+---------------+--------------------+------------------+--------------------+--------------------+----------------+----------------------+--------------+---------------------+------------------+------------------+----------------+-------------------------+-----------------+-----------------+------------------+-----------------+-----------------+----------------+---------------------+--------------+--------------------+-----------------------+-------------+------------------+--------------------+---------------------------+-----------------------+-------------------+---------------------+-----------------+-----------------+--------------------+--------------------+------------------+------------------+---------------------+------------------+-------------------+------------------+-------------------+------------------+-----------------------+----------------+----------------+------------------+----------------+--------------------+-----------------+---------------+--------------------+---------------+-----------------------+-----------------+-----------------------+---------------+-------------------------+-------------------------+--------------+-----------------------+---------------+--------------+--------------------+-------------------+--------------------+------------------+--------------------+-----------------+--------------------+------------------+---------------------------+-----------------+---------------+--------------------------+----------------------+--------------------+----------------------+----------------+-----------------+----------------+----------------------+---------------------+---------------+-----------------+----------------------+------------------+------------------+---------------+---------------------+----------------+---------------+-----------------+------------------+----------------+--------------+------------------+---------------+-----------------+--------------------+-----------------+----------------+---------------+------------------+-------------------------+------------------+---------------+-------------+-------------------------+----------------+-----------------------+------------------------+---------------------+--------------------------+----------------+-----------------+------------------+-------------------+---------------+--------------+--------------------+----------------------+-----------------+-----------------------+------------------------+-----------------+----------------------+----------------+---------------+----------------------+-------------+----------------------------+---------------------+-----------------+-----------------------------+--------------------+-----------------+------------------+-----------------------+----------------+-------------+----------------------+---------------+-------------------+-------------------+--------------------+----------------------------+---------------+---------------------------+--------------------+------------------+------------------+-------------------+----------------+-----------------+-------------------+---------------+-----------------+-----------------+------------------+------------------+--------------------+------------------+--------------------+-----------------+----------------+----------------+-----------------+-------------------+--------------------+-----------------+-------------------+---------------------------+------------------------+----------------------+----------------+----------------------------+---------------------+-----------------------+---------------+-----------------+-----------------------+-------------------+----------------------+----------------------+-----------------+---------------------+-------------------+-----------------+---------------+---------------+-----------------+-----------------+---------------------+-------------------------+----------------+------------------+------------------------+-----------------+----------------+----------------+------------------+-----------------+---------------+-------------------+------------------+--------------------+-----------------+-----------------+-------------------+--------------+-----------------+---------------------+---------------+-------------------------+----------------------+------+\n",
      "|street|image_id|n_citi|bed|bath|sqft|citi_Mojave, CA|citi_Gorman, CA|citi_Ontario, CA|citi_Creston, CA|citi_Rancho Mirage, CA|citi_Stevenson Ranch, CA|citi_Hemet, CA|citi_Palm Springs, CA|citi_Santa Paula, CA|citi_Altadena, CA|citi_Bell Gardens, CA|citi_La Habra, CA|citi_La Crescenta, CA|citi_Salton City, CA|citi_Los Feliz, CA|citi_West Hollywood, CA|citi_Costa Mesa, CA|citi_Wofford Heights, CA|citi_Montebello, CA|citi_Rimforest, CA|citi_North Tustin, CA|citi_North Hollywood, CA|citi_Compton, CA|citi_Saugus, CA|citi_Barstow, CA|citi_South Gate, CA|citi_Loma Linda, CA|citi_Lemon Grove, CA|citi_Fountain Valley, CA|citi_Cedar Glen, CA|citi_Jamul, CA|citi_Bonsall, CA|citi_Hawthorne, CA|citi_San Fernando, CA|citi_Seal Beach, CA|citi_Big Bear, CA|citi_San Dimas, CA|citi_Cerritos, CA|citi_Aguanga, CA|citi_Bakersfield, CA|citi_Walnut, CA|citi_Pasadena, CA|citi_Anaheim Hills, CA|citi_Oro Grande, CA|citi_Santa Ysabel, CA|citi_Lake Los Angeles, CA|citi_Needles, CA|citi_La Canada Flintridge, CA|citi_West Covina, CA|citi_Ocean Beach, CA|citi_Victorville, CA|citi_Studio City, CA|citi_Montecito, CA|citi_Atascadero, CA|citi_Hollywood, CA|citi_Cabazon, CA|citi_Crestline, CA|citi_Parkfield, CA|citi_California City, CA|citi_Silverado, CA|citi_Pine Valley, CA|citi_Lake Sherwood, CA|citi_Port Hueneme, CA|citi_Downey, CA|citi_Laguna Woods, CA|citi_Covina, CA|citi_Stallion Springs, CA|citi_Piru, CA|citi_El Segundo, CA|citi_Mission Hills, CA|citi_Redondo Beach, CA|citi_Upland, CA|citi_Alta Loma, CA|citi_Big Bear City, CA|citi_Canyon Country, CA|citi_Pearblossom, CA|citi_Lawndale, CA|citi_Moorpark, CA|citi_Tarzana, CA|citi_La Puente, CA|citi_Baldwin Park, CA|citi_Ridgecrest, CA|citi_Toluca Lake, CA|citi_Yorba Linda, CA|citi_Homeland, CA|citi_Venice, CA|citi_Modjeska Canyon, CA|citi_Nuevo, CA|citi_Mentone, CA|citi_Sun Valley, CA|citi_La Verne, CA|citi_Fullerton, CA|citi_La Mesa, CA|citi_Jacumba, CA|citi_Temple City, CA|citi_Grover Beach, CA|citi_Cedarpines Park, CA|citi_Valley Center, CA|citi_Shandon, CA|citi_Monrovia, CA|citi_Campo, CA|citi_Cherry Valley, CA|citi_Spring Valley, CA|citi_Mountain Center, CA|citi_Thermal, CA|citi_Los Alamitos, CA|citi_Rancho Bernardo, CA|citi_Hermosa Beach, CA|citi_South El Monte, CA|citi_Moreno Valley, CA|citi_Brawley, CA|citi_Joshua Tree, CA|citi_Pacific Beach, CA|citi_Templeton, CA|citi_Eagle Rock, CA|citi_Hacienda Heights, CA|citi_Norco, CA|citi_Apple Valley, CA|citi_Carpinteria, CA|citi_Acton, CA|citi_La Mirada, CA|citi_Murrieta, CA|citi_Phelan, CA|citi_Calexico, CA|citi_Santa Fe Springs, CA|citi_Chino, CA|citi_Santa Clarita, CA|citi_Blythe, CA|citi_Lucerne Valley, CA|citi_Warner Springs, CA|citi_Belltown, CA|citi_Rancho Santa Fe, CA|citi_Nipomo, CA|citi_Lake Elizabeth, CA|citi_Huntington Park, CA|citi_Pico Rivera, CA|citi_Highland Park, CA|citi_Whitewater, CA|citi_New Cuyama, CA|citi_Porter Ranch, CA|citi_Shadow Hills, CA|citi_Norwalk, CA|citi_Yucca Valley, CA|citi_Forest Falls, CA|citi_Solana Beach, CA|citi_Cayucos, CA|citi_Lakewood, CA|citi_Wrightwood, CA|citi_Encino, CA|citi_Los Angeles, CA|citi_North Hills, CA|citi_Corona, CA|citi_Buellton, CA|citi_Somis, CA|citi_Lebec, CA|citi_Carlsbad, CA|citi_Dulzura, CA|citi_Claremont, CA|citi_Lake Elsinore, CA|citi_Camarillo, CA|citi_Valley Glen, CA|citi_Rancho Cucamonga, CA|citi_San Gabriel, CA|citi_Malibu, CA|citi_Palmdale, CA|citi_Calimesa, CA|citi_Lynwood, CA|citi_Ramona, CA|citi_Newhall, CA|citi_Rosamond, CA|citi_Highland, CA|citi_Canyon Lake, CA|citi_Caliente, CA|citi_Diamond Bar, CA|citi_Indio, CA|citi_National City, CA|citi_Torrance, CA|citi_Rowland Heights, CA|citi_Lakeview Terrace, CA|citi_Arroyo Grande, CA|citi_Tehachapi, CA|citi_Littlerock, CA|citi_Westminster, CA|citi_Villa Park, CA|citi_Cypress, CA|citi_San Diego, CA|citi_South Pasadena, CA|citi_Leona Valley, CA|citi_Rosemead, CA|citi_Newbury Park, CA|citi_Frazier Park, CA|citi_Rancho Santa Margarita, CA|citi_San Marcos, CA|citi_Green Valley, CA|citi_Carson, CA|citi_Newport Coast, CA|citi_Grand Terrace, CA|citi_Valley Village, CA|citi_Laguna Hills, CA|citi_Winnetka, CA|citi_Tustin, CA|citi_Pinon Hills, CA|citi_Oceanside, CA|citi_Palm Desert, CA|citi_Paso Robles, CA|citi_Tujunga, CA|citi_Mission Viejo, CA|citi_Arvin, CA|citi_Santa Monica, CA|citi_Idyllwild, CA|citi_Boulevard, CA|citi_Potrero, CA|citi_Newberry Springs, CA|citi_Oak Glen, CA|citi_Blue Jay, CA|citi_Oak Hills, CA|citi_Van Nuys, CA|citi_Wildomar, CA|citi_Solvang, CA|citi_Sierra Madre, CA|citi_Poway, CA|citi_Lake Hughes, CA|citi_Phillips Ranch, CA|citi_Brea, CA|citi_San Pedro, CA|citi_Pismo Beach, CA|citi_Vandenberg Village, CA|citi_Woodland Hills, CA|citi_San Marino, CA|citi_Indian Wells, CA|citi_Lakeside, CA|citi_Fillmore, CA|citi_San Jacinto, CA|citi_Lake Forest, CA|citi_Coachella, CA|citi_Morro Bay, CA|citi_Garden Grove, CA|citi_Placentia, CA|citi_Los Alamos, CA|citi_El Mirage, CA|citi_Santa Ynez, CA|citi_Kernville, CA|citi_Thousand Palms, CA|citi_Anaheim, CA|citi_Ventura, CA|citi_Riverside, CA|citi_Cardiff, CA|citi_Santa Maria, CA|citi_La Palma, CA|citi_Oxnard, CA|citi_Quartz Hill, CA|citi_Arleta, CA|citi_Paradise Hills, CA|citi_Los Osos, CA|citi_Corona del Mar, CA|citi_Irvine, CA|citi_Palomar Mountain, CA|citi_Westlake Village, CA|citi_Azusa, CA|citi_San Bernardino, CA|citi_Delano, CA|citi_Llano, CA|citi_Canoga Park, CA|citi_Wilmington, CA|citi_Lake Balboa, CA|citi_Sugarloaf, CA|citi_Simi Valley, CA|citi_El Monte, CA|citi_Pioneertown, CA|citi_Big River, CA|citi_Cardiff by the Sea, CA|citi_Glendale, CA|citi_Duarte, CA|citi_Green Valley Lake, CA|citi_Monterey Park, CA|citi_Harbor City, CA|citi_Santa Barbara, CA|citi_Banning, CA|citi_Redlands, CA|citi_Arcadia, CA|citi_Bermuda Dunes, CA|citi_Angelus Oaks, CA|citi_Bonita, CA|citi_Glendora, CA|citi_Panorama City, CA|citi_Guadalupe, CA|citi_Helendale, CA|citi_Cuyama, CA|citi_Coto de Caza, CA|citi_Pacoima, CA|citi_Oceano, CA|citi_Oak Park, CA|citi_Val Verde, CA|citi_Fontana, CA|citi_Vista, CA|citi_View Park, CA|citi_Perris, CA|citi_Descanso, CA|citi_La Conchita, CA|citi_Hesperia, CA|citi_Del Mar, CA|citi_Santee, CA|citi_Inglewood, CA|citi_East Los Angeles, CA|citi_Calabasas, CA|citi_Orange, CA|citi_Anza, CA|citi_Hawaiian Gardens, CA|citi_Artesia, CA|citi_Morongo Valley, CA|citi_Santa Margarita, CA|citi_Agoura Hills, CA|citi_Pacific Palisades, CA|citi_Menifee, CA|citi_Sun City, CA|citi_Mira Loma, CA|citi_Twin Peaks, CA|citi_Lompoc, CA|citi_Boron, CA|citi_Culver City, CA|citi_Laguna Niguel, CA|citi_Beaumont, CA|citi_Lake Arrowhead, CA|citi_Running Springs, CA|citi_Whittier, CA|citi_Playa del Rey, CA|citi_Topanga, CA|citi_Alpine, CA|citi_Beverly Hills, CA|citi_Bell, CA|citi_San Juan Capistrano, CA|citi_San Clemente, CA|citi_La Jolla, CA|citi_Palos Verdes Estates, CA|citi_Bloomington, CA|citi_El Cajon, CA|citi_Encinitas, CA|citi_Cathedral City, CA|citi_Yucaipa, CA|citi_Ojai, CA|citi_Newport Beach, CA|citi_Rialto, CA|citi_Long Beach, CA|citi_Chatsworth, CA|citi_Avila Beach, CA|citi_Rancho Palos Verdes, CA|citi_Reseda, CA|citi_Pine Mountain Club, CA|citi_Westchester, CA|citi_Lancaster, CA|citi_Paramount, CA|citi_West Hills, CA|citi_Gardena, CA|citi_Montrose, CA|citi_Winchester, CA|citi_Colton, CA|citi_Imperial, CA|citi_Rossmoor, CA|citi_Santa Ana, CA|citi_Montclair, CA|citi_Chula Vista, CA|citi_Fallbrook, CA|citi_Midway City, CA|citi_Temecula, CA|citi_Cambria, CA|citi_Sunland, CA|citi_Mt Baldy, CA|citi_Buena Park, CA|citi_Aliso Viejo, CA|citi_Ranchita, CA|citi_Dana Point, CA|citi_Desert Hot Springs, CA|citi_Borrego Springs, CA|citi_Thousand Oaks, CA|citi_Stanton, CA|citi_Bear Valley Springs, CA|citi_Sherman Oaks, CA|citi_Trabuco Canyon, CA|citi_Lomita, CA|citi_Adelanto, CA|citi_Imperial Beach, CA|citi_Northridge, CA|citi_Juniper Hills, CA|citi_Granada Hills, CA|citi_Valencia, CA|citi_Pauma Valley, CA|citi_Agua Dulce, CA|citi_Coronado, CA|citi_Julian, CA|citi_Sylmar, CA|citi_Romoland, CA|citi_Commerce, CA|citi_Laguna Beach, CA|citi_La Habra Heights, CA|citi_Landers, CA|citi_Escondido, CA|citi_San Luis Obispo, CA|citi_Oak View, CA|citi_Castaic, CA|citi_Burbank, CA|citi_La Quinta, CA|citi_29 Palms, CA|citi_Pomona, CA|citi_San Miguel, CA|citi_Echo Park, CA|citi_Chino Hills, CA|citi_Fawnskin, CA|citi_Inyokern, CA|citi_Bellflower, CA|citi_Keene, CA|citi_Alhambra, CA|citi_Ladera Ranch, CA|citi_Goleta, CA|citi_Huntington Beach, CA|citi_Big Bear Lake, CA|price |\n",
      "+------+--------+------+---+----+----+---------------+---------------+----------------+----------------+----------------------+------------------------+--------------+---------------------+--------------------+-----------------+---------------------+-----------------+---------------------+--------------------+------------------+-----------------------+-------------------+------------------------+-------------------+------------------+---------------------+------------------------+----------------+---------------+----------------+-------------------+-------------------+--------------------+------------------------+-------------------+--------------+----------------+------------------+---------------------+-------------------+-----------------+------------------+-----------------+----------------+--------------------+---------------+-----------------+----------------------+-------------------+---------------------+-------------------------+----------------+-----------------------------+--------------------+--------------------+--------------------+--------------------+------------------+-------------------+------------------+----------------+------------------+------------------+------------------------+------------------+--------------------+----------------------+---------------------+---------------+---------------------+---------------+-------------------------+-------------+-------------------+----------------------+----------------------+---------------+------------------+----------------------+-----------------------+--------------------+-----------------+-----------------+----------------+------------------+---------------------+-------------------+--------------------+--------------------+-----------------+---------------+------------------------+--------------+----------------+-------------------+-----------------+------------------+----------------+----------------+--------------------+---------------------+------------------------+----------------------+----------------+-----------------+--------------+----------------------+----------------------+------------------------+----------------+---------------------+------------------------+----------------------+-----------------------+----------------------+----------------+--------------------+----------------------+------------------+-------------------+-------------------------+--------------+---------------------+--------------------+--------------+------------------+-----------------+---------------+-----------------+-------------------------+--------------+----------------------+---------------+-----------------------+-----------------------+-----------------+------------------------+---------------+-----------------------+------------------------+--------------------+----------------------+-------------------+-------------------+---------------------+---------------------+----------------+---------------------+---------------------+---------------------+----------------+-----------------+-------------------+---------------+--------------------+--------------------+---------------+-----------------+--------------+--------------+-----------------+----------------+------------------+----------------------+------------------+--------------------+-------------------------+--------------------+---------------+-----------------+-----------------+----------------+---------------+----------------+-----------------+-----------------+--------------------+-----------------+--------------------+--------------+----------------------+-----------------+------------------------+-------------------------+----------------------+------------------+-------------------+--------------------+-------------------+----------------+------------------+-----------------------+---------------------+-----------------+---------------------+---------------------+-------------------------------+-------------------+---------------------+---------------+----------------------+----------------------+-----------------------+---------------------+-----------------+---------------+--------------------+------------------+--------------------+--------------------+----------------+----------------------+--------------+---------------------+------------------+------------------+----------------+-------------------------+-----------------+-----------------+------------------+-----------------+-----------------+----------------+---------------------+--------------+--------------------+-----------------------+-------------+------------------+--------------------+---------------------------+-----------------------+-------------------+---------------------+-----------------+-----------------+--------------------+--------------------+------------------+------------------+---------------------+------------------+-------------------+------------------+-------------------+------------------+-----------------------+----------------+----------------+------------------+----------------+--------------------+-----------------+---------------+--------------------+---------------+-----------------------+-----------------+-----------------------+---------------+-------------------------+-------------------------+--------------+-----------------------+---------------+--------------+--------------------+-------------------+--------------------+------------------+--------------------+-----------------+--------------------+------------------+---------------------------+-----------------+---------------+--------------------------+----------------------+--------------------+----------------------+----------------+-----------------+----------------+----------------------+---------------------+---------------+-----------------+----------------------+------------------+------------------+---------------+---------------------+----------------+---------------+-----------------+------------------+----------------+--------------+------------------+---------------+-----------------+--------------------+-----------------+----------------+---------------+------------------+-------------------------+------------------+---------------+-------------+-------------------------+----------------+-----------------------+------------------------+---------------------+--------------------------+----------------+-----------------+------------------+-------------------+---------------+--------------+--------------------+----------------------+-----------------+-----------------------+------------------------+-----------------+----------------------+----------------+---------------+----------------------+-------------+----------------------------+---------------------+-----------------+-----------------------------+--------------------+-----------------+------------------+-----------------------+----------------+-------------+----------------------+---------------+-------------------+-------------------+--------------------+----------------------------+---------------+---------------------------+--------------------+------------------+------------------+-------------------+----------------+-----------------+-------------------+---------------+-----------------+-----------------+------------------+------------------+--------------------+------------------+--------------------+-----------------+----------------+----------------+-----------------+-------------------+--------------------+-----------------+-------------------+---------------------------+------------------------+----------------------+----------------+----------------------------+---------------------+-----------------------+---------------+-----------------+-----------------------+-------------------+----------------------+----------------------+-----------------+---------------------+-------------------+-----------------+---------------+---------------+-----------------+-----------------+---------------------+-------------------------+----------------+------------------+------------------------+-----------------+----------------+----------------+------------------+-----------------+---------------+-------------------+------------------+--------------------+-----------------+-----------------+-------------------+--------------+-----------------+---------------------+---------------+-------------------------+----------------------+------+\n",
      "|1     |1       |48    |3  |2   |713 |0              |0              |0               |0               |0                     |0                       |0             |0                    |0                   |0                |0                    |0                |0                    |0                   |0                 |0                      |0                  |0                       |0                  |0                 |0                    |0                       |0               |0              |0               |0                  |0                  |0                   |0                       |0                  |0             |0               |0                 |0                    |0                  |0                |0                 |0                |0               |0                   |0              |0                |0                     |0                  |0                    |0                        |0               |0                            |0                   |0                   |0                   |0                   |0                 |0                  |0                 |0               |0                 |0                 |0                       |0                 |0                   |0                     |0                    |0              |0                    |0              |0                        |0            |0                  |0                     |0                     |0              |0                 |0                     |0                      |0                   |0                |0                |0               |0                 |0                    |0                  |0                   |0                   |0                |0              |0                       |0             |0               |0                  |0                |0                 |0               |0               |0                   |0                    |0                       |0                     |0               |0                |0             |0                     |0                     |0                       |0               |0                    |0                       |0                     |0                      |0                     |1               |0                   |0                     |0                 |0                  |0                        |0             |0                    |0                   |0             |0                 |0                |0              |0                |0                        |0             |0                     |0              |0                      |0                      |0                |0                       |0              |0                      |0                       |0                   |0                     |0                  |0                  |0                    |0                    |0               |0                    |0                    |0                    |0               |0                |0                  |0              |0                   |0                   |0              |0                |0             |0             |0                |0               |0                 |0                     |0                 |0                   |0                        |0                   |0              |0                |0                |0               |0              |0               |0                |0                |0                   |0                |0                   |0             |0                     |0                |0                       |0                        |0                     |0                 |0                  |0                   |0                  |0               |0                 |0                      |0                    |0                |0                    |0                    |0                              |0                  |0                    |0              |0                     |0                     |0                      |0                    |0                |0              |0                   |0                 |0                   |0                   |0               |0                     |0             |0                    |0                 |0                 |0               |0                        |0                |0                |0                 |0                |0                |0               |0                    |0             |0                   |0                      |0            |0                 |0                   |0                          |0                      |0                  |0                    |0                |0                |0                   |0                   |0                 |0                 |0                    |0                 |0                  |0                 |0                  |0                 |0                      |0               |0               |0                 |0               |0                   |0                |0              |0                   |0              |0                      |0                |0                      |0              |0                        |0                        |0             |0                      |0              |0             |0                   |0                  |0                   |0                 |0                   |0                |0                   |0                 |0                          |0                |0              |0                         |0                     |0                   |0                     |0               |0                |0               |0                     |0                    |0              |0                |0                     |0                 |0                 |0              |0                    |0               |0              |0                |0                 |0               |0             |0                 |0              |0                |0                   |0                |0               |0              |0                 |0                        |0                 |0              |0            |0                        |0               |0                      |0                       |0                    |0                         |0               |0                |0                 |0                  |0              |0             |0                   |0                     |0                |0                      |0                       |0                |0                     |0               |0              |0                     |0            |0                           |0                    |0                |0                            |0                   |0                |0                 |0                      |0               |0            |0                     |0              |0                  |0                  |0                   |0                           |0              |0                          |0                   |0                 |0                 |0                  |0               |0                |0                  |0              |0                |0                |0                 |0                 |0                   |0                 |0                   |0                |0               |0               |0                |0                  |0                   |0                |0                  |0                          |0                       |0                     |0               |0                           |0                    |0                      |0              |0                |0                      |0                  |0                     |0                     |0                |0                    |0                  |0                |0              |0              |0                |0                |0                    |0                        |0               |0                 |0                       |0                |0               |0               |0                 |0                |0              |0                  |0                 |0                   |0                |0                |0                  |0             |0                |0                    |0              |0                        |0                     |228500|\n",
      "|1     |2       |152   |3  |1   |800 |0              |0              |0               |0               |0                     |0                       |0             |0                    |0                   |0                |0                    |0                |0                    |0                   |0                 |0                      |0                  |0                       |0                  |0                 |0                    |0                       |0               |0              |0               |0                  |0                  |0                   |0                       |0                  |0             |0               |0                 |0                    |0                  |0                |0                 |0                |0               |0                   |0              |0                |0                     |0                  |0                    |0                        |0               |0                            |0                   |0                   |0                   |0                   |0                 |0                  |0                 |0               |0                 |0                 |0                       |0                 |0                   |0                     |0                    |0              |0                    |0              |0                        |0            |0                  |0                     |0                     |0              |0                 |0                     |0                      |0                   |0                |0                |0               |0                 |0                    |0                  |0                   |0                   |0                |0              |0                       |0             |0               |0                  |0                |0                 |0               |0               |0                   |0                    |0                       |0                     |0               |0                |0             |0                     |0                     |0                       |0               |0                    |0                       |0                     |0                      |0                     |0               |0                   |0                     |0                 |0                  |0                        |0             |0                    |0                   |0             |0                 |0                |0              |0                |0                        |0             |0                     |0              |0                      |0                      |0                |0                       |0              |0                      |0                       |0                   |0                     |0                  |0                  |0                    |0                    |0               |0                    |0                    |0                    |0               |0                |0                  |0              |0                   |0                   |0              |0                |0             |0             |0                |0               |0                 |0                     |0                 |0                   |0                        |0                   |0              |0                |0                |0               |0              |0               |0                |0                |0                   |0                |0                   |0             |0                     |0                |0                       |0                        |0                     |0                 |0                  |0                   |0                  |0               |0                 |0                      |0                    |0                |0                    |0                    |0                              |0                  |0                    |0              |0                     |0                     |0                      |0                    |0                |0              |0                   |0                 |0                   |0                   |0               |0                     |0             |0                    |0                 |0                 |0               |0                        |0                |0                |0                 |0                |0                |0               |0                    |0             |0                   |0                      |0            |0                 |0                   |0                          |0                      |0                  |0                    |0                |0                |0                   |0                   |0                 |0                 |0                    |0                 |0                  |0                 |0                  |0                 |0                      |0               |0               |0                 |0               |0                   |0                |0              |0                   |0              |0                      |0                |0                      |0              |0                        |0                        |0             |0                      |0              |0             |0                   |0                  |0                   |0                 |0                   |0                |0                   |0                 |0                          |0                |0              |0                         |0                     |0                   |0                     |0               |0                |0               |0                     |0                    |0              |0                |0                     |0                 |0                 |0              |0                    |0               |0              |0                |0                 |0               |0             |0                 |0              |0                |0                   |0                |0               |0              |0                 |0                        |0                 |0              |0            |0                        |0               |0                      |0                       |0                    |0                         |0               |0                |0                 |0                  |0              |0             |0                   |0                     |0                |0                      |0                       |0                |0                     |0               |0              |0                     |0            |0                           |0                    |0                |0                            |0                   |0                |0                 |0                      |0               |0            |0                     |0              |0                  |0                  |0                   |0                           |0              |0                          |0                   |0                 |0                 |0                  |0               |0                |0                  |0              |1                |0                |0                 |0                 |0                   |0                 |0                   |0                |0               |0               |0                |0                  |0                   |0                |0                  |0                          |0                       |0                     |0               |0                           |0                    |0                      |0              |0                |0                      |0                  |0                     |0                     |0                |0                    |0                  |0                |0              |0              |0                |0                |0                    |0                        |0               |0                 |0                       |0                |0               |0               |0                 |0                |0              |0                  |0                 |0                   |0                |0                |0                  |0             |0                |0                    |0              |0                        |0                     |273950|\n",
      "|1     |3       |48    |3  |1   |1082|0              |0              |0               |0               |0                     |0                       |0             |0                    |0                   |0                |0                    |0                |0                    |0                   |0                 |0                      |0                  |0                       |0                  |0                 |0                    |0                       |0               |0              |0               |0                  |0                  |0                   |0                       |0                  |0             |0               |0                 |0                    |0                  |0                |0                 |0                |0               |0                   |0              |0                |0                     |0                  |0                    |0                        |0               |0                            |0                   |0                   |0                   |0                   |0                 |0                  |0                 |0               |0                 |0                 |0                       |0                 |0                   |0                     |0                    |0              |0                    |0              |0                        |0            |0                  |0                     |0                     |0              |0                 |0                     |0                      |0                   |0                |0                |0               |0                 |0                    |0                  |0                   |0                   |0                |0              |0                       |0             |0               |0                  |0                |0                 |0               |0               |0                   |0                    |0                       |0                     |0               |0                |0             |0                     |0                     |0                       |0               |0                    |0                       |0                     |0                      |0                     |1               |0                   |0                     |0                 |0                  |0                        |0             |0                    |0                   |0             |0                 |0                |0              |0                |0                        |0             |0                     |0              |0                      |0                      |0                |0                       |0              |0                      |0                       |0                   |0                     |0                  |0                  |0                    |0                    |0               |0                    |0                    |0                    |0               |0                |0                  |0              |0                   |0                   |0              |0                |0             |0             |0                |0               |0                 |0                     |0                 |0                   |0                        |0                   |0              |0                |0                |0               |0              |0               |0                |0                |0                   |0                |0                   |0             |0                     |0                |0                       |0                        |0                     |0                 |0                  |0                   |0                  |0               |0                 |0                      |0                    |0                |0                    |0                    |0                              |0                  |0                    |0              |0                     |0                     |0                      |0                    |0                |0              |0                   |0                 |0                   |0                   |0               |0                     |0             |0                    |0                 |0                 |0               |0                        |0                |0                |0                 |0                |0                |0               |0                    |0             |0                   |0                      |0            |0                 |0                   |0                          |0                      |0                  |0                    |0                |0                |0                   |0                   |0                 |0                 |0                    |0                 |0                  |0                 |0                  |0                 |0                      |0               |0               |0                 |0               |0                   |0                |0              |0                   |0              |0                      |0                |0                      |0              |0                        |0                        |0             |0                      |0              |0             |0                   |0                  |0                   |0                 |0                   |0                |0                   |0                 |0                          |0                |0              |0                         |0                     |0                   |0                     |0               |0                |0               |0                     |0                    |0              |0                |0                     |0                 |0                 |0              |0                    |0               |0              |0                |0                 |0               |0             |0                 |0              |0                |0                   |0                |0               |0              |0                 |0                        |0                 |0              |0            |0                        |0               |0                      |0                       |0                    |0                         |0               |0                |0                 |0                  |0              |0             |0                   |0                     |0                |0                      |0                       |0                |0                     |0               |0              |0                     |0            |0                           |0                    |0                |0                            |0                   |0                |0                 |0                      |0               |0            |0                     |0              |0                  |0                  |0                   |0                           |0              |0                          |0                   |0                 |0                 |0                  |0               |0                |0                  |0              |0                |0                |0                 |0                 |0                   |0                 |0                   |0                |0               |0               |0                |0                  |0                   |0                |0                  |0                          |0                       |0                     |0               |0                           |0                    |0                      |0              |0                |0                      |0                  |0                     |0                     |0                |0                    |0                  |0                |0              |0              |0                |0                |0                    |0                        |0               |0                 |0                       |0                |0               |0               |0                 |0                |0              |0                  |0                 |0                   |0                |0                |0                  |0             |0                |0                    |0              |0                        |0                     |350000|\n",
      "|1     |4       |55    |4  |3   |2547|0              |0              |0               |0               |0                     |0                       |0             |0                    |0                   |0                |0                    |0                |0                    |0                   |0                 |0                      |0                  |0                       |0                  |0                 |0                    |0                       |0               |0              |0               |0                  |0                  |0                   |0                       |0                  |0             |0               |0                 |0                    |0                  |0                |0                 |0                |0               |0                   |0              |0                |0                     |0                  |0                    |0                        |0               |0                            |0                   |0                   |0                   |0                   |0                 |0                  |0                 |0               |0                 |0                 |0                       |0                 |0                   |0                     |0                    |0              |0                    |0              |0                        |0            |0                  |0                     |0                     |0              |0                 |0                     |0                      |0                   |0                |0                |0               |0                 |0                    |0                  |0                   |0                   |0                |0              |0                       |0             |0               |0                  |0                |0                 |0               |0               |0                   |0                    |0                       |0                     |0               |0                |0             |0                     |0                     |0                       |0               |0                    |0                       |0                     |0                      |0                     |0               |0                   |0                     |0                 |0                  |0                        |0             |0                    |0                   |0             |0                 |0                |0              |1                |0                        |0             |0                     |0              |0                      |0                      |0                |0                       |0              |0                      |0                       |0                   |0                     |0                  |0                  |0                    |0                    |0               |0                    |0                    |0                    |0               |0                |0                  |0              |0                   |0                   |0              |0                |0             |0             |0                |0               |0                 |0                     |0                 |0                   |0                        |0                   |0              |0                |0                |0               |0              |0               |0                |0                |0                   |0                |0                   |0             |0                     |0                |0                       |0                        |0                     |0                 |0                  |0                   |0                  |0               |0                 |0                      |0                    |0                |0                    |0                    |0                              |0                  |0                    |0              |0                     |0                     |0                      |0                    |0                |0              |0                   |0                 |0                   |0                   |0               |0                     |0             |0                    |0                 |0                 |0               |0                        |0                |0                |0                 |0                |0                |0               |0                    |0             |0                   |0                      |0            |0                 |0                   |0                          |0                      |0                  |0                    |0                |0                |0                   |0                   |0                 |0                 |0                    |0                 |0                  |0                 |0                  |0                 |0                      |0               |0               |0                 |0               |0                   |0                |0              |0                   |0              |0                      |0                |0                      |0              |0                        |0                        |0             |0                      |0              |0             |0                   |0                  |0                   |0                 |0                   |0                |0                   |0                 |0                          |0                |0              |0                         |0                     |0                   |0                     |0               |0                |0               |0                     |0                    |0              |0                |0                     |0                 |0                 |0              |0                    |0               |0              |0                |0                 |0               |0             |0                 |0              |0                |0                   |0                |0               |0              |0                 |0                        |0                 |0              |0            |0                        |0               |0                      |0                       |0                    |0                         |0               |0                |0                 |0                  |0              |0             |0                   |0                     |0                |0                      |0                       |0                |0                     |0               |0              |0                     |0            |0                           |0                    |0                |0                            |0                   |0                |0                 |0                      |0               |0            |0                     |0              |0                  |0                  |0                   |0                           |0              |0                          |0                   |0                 |0                 |0                  |0               |0                |0                  |0              |0                |0                |0                 |0                 |0                   |0                 |0                   |0                |0               |0               |0                |0                  |0                   |0                |0                  |0                          |0                       |0                     |0               |0                           |0                    |0                      |0              |0                |0                      |0                  |0                     |0                     |0                |0                    |0                  |0                |0              |0              |0                |0                |0                    |0                        |0               |0                 |0                       |0                |0               |0               |0                 |0                |0              |0                  |0                 |0                   |0                |0                |0                  |0             |0                |0                    |0              |0                        |0                     |385100|\n",
      "|1     |6       |55    |4  |3   |2769|0              |0              |0               |0               |0                     |0                       |0             |0                    |0                   |0                |0                    |0                |0                    |0                   |0                 |0                      |0                  |0                       |0                  |0                 |0                    |0                       |0               |0              |0               |0                  |0                  |0                   |0                       |0                  |0             |0               |0                 |0                    |0                  |0                |0                 |0                |0               |0                   |0              |0                |0                     |0                  |0                    |0                        |0               |0                            |0                   |0                   |0                   |0                   |0                 |0                  |0                 |0               |0                 |0                 |0                       |0                 |0                   |0                     |0                    |0              |0                    |0              |0                        |0            |0                  |0                     |0                     |0              |0                 |0                     |0                      |0                   |0                |0                |0               |0                 |0                    |0                  |0                   |0                   |0                |0              |0                       |0             |0               |0                  |0                |0                 |0               |0               |0                   |0                    |0                       |0                     |0               |0                |0             |0                     |0                     |0                       |0               |0                    |0                       |0                     |0                      |0                     |0               |0                   |0                     |0                 |0                  |0                        |0             |0                    |0                   |0             |0                 |0                |0              |1                |0                        |0             |0                     |0              |0                      |0                      |0                |0                       |0              |0                      |0                       |0                   |0                     |0                  |0                  |0                    |0                    |0               |0                    |0                    |0                    |0               |0                |0                  |0              |0                   |0                   |0              |0                |0             |0             |0                |0               |0                 |0                     |0                 |0                   |0                        |0                   |0              |0                |0                |0               |0              |0               |0                |0                |0                   |0                |0                   |0             |0                     |0                |0                       |0                        |0                     |0                 |0                  |0                   |0                  |0               |0                 |0                      |0                    |0                |0                    |0                    |0                              |0                  |0                    |0              |0                     |0                     |0                      |0                    |0                |0              |0                   |0                 |0                   |0                   |0               |0                     |0             |0                    |0                 |0                 |0               |0                        |0                |0                |0                 |0                |0                |0               |0                    |0             |0                   |0                      |0            |0                 |0                   |0                          |0                      |0                  |0                    |0                |0                |0                   |0                   |0                 |0                 |0                    |0                 |0                  |0                 |0                  |0                 |0                      |0               |0               |0                 |0               |0                   |0                |0              |0                   |0              |0                      |0                |0                      |0              |0                        |0                        |0             |0                      |0              |0             |0                   |0                  |0                   |0                 |0                   |0                |0                   |0                 |0                          |0                |0              |0                         |0                     |0                   |0                     |0               |0                |0               |0                     |0                    |0              |0                |0                     |0                 |0                 |0              |0                    |0               |0              |0                |0                 |0               |0             |0                 |0              |0                |0                   |0                |0               |0              |0                 |0                        |0                 |0              |0            |0                        |0               |0                      |0                       |0                    |0                         |0               |0                |0                 |0                  |0              |0             |0                   |0                     |0                |0                      |0                       |0                |0                     |0               |0              |0                     |0            |0                           |0                    |0                |0                            |0                   |0                |0                 |0                      |0               |0            |0                     |0              |0                  |0                  |0                   |0                           |0              |0                          |0                   |0                 |0                 |0                  |0               |0                |0                  |0              |0                |0                |0                 |0                 |0                   |0                 |0                   |0                |0               |0               |0                |0                  |0                   |0                |0                  |0                          |0                       |0                     |0               |0                           |0                    |0                      |0              |0                |0                      |0                  |0                     |0                     |0                |0                    |0                  |0                |0              |0              |0                |0                |0                    |0                        |0               |0                 |0                       |0                |0               |0               |0                 |0                |0              |0                  |0                 |0                   |0                |0                |0                  |0             |0                |0                    |0              |0                        |0                     |415000|\n",
      "+------+--------+------+---+----+----+---------------+---------------+----------------+----------------+----------------------+------------------------+--------------+---------------------+--------------------+-----------------+---------------------+-----------------+---------------------+--------------------+------------------+-----------------------+-------------------+------------------------+-------------------+------------------+---------------------+------------------------+----------------+---------------+----------------+-------------------+-------------------+--------------------+------------------------+-------------------+--------------+----------------+------------------+---------------------+-------------------+-----------------+------------------+-----------------+----------------+--------------------+---------------+-----------------+----------------------+-------------------+---------------------+-------------------------+----------------+-----------------------------+--------------------+--------------------+--------------------+--------------------+------------------+-------------------+------------------+----------------+------------------+------------------+------------------------+------------------+--------------------+----------------------+---------------------+---------------+---------------------+---------------+-------------------------+-------------+-------------------+----------------------+----------------------+---------------+------------------+----------------------+-----------------------+--------------------+-----------------+-----------------+----------------+------------------+---------------------+-------------------+--------------------+--------------------+-----------------+---------------+------------------------+--------------+----------------+-------------------+-----------------+------------------+----------------+----------------+--------------------+---------------------+------------------------+----------------------+----------------+-----------------+--------------+----------------------+----------------------+------------------------+----------------+---------------------+------------------------+----------------------+-----------------------+----------------------+----------------+--------------------+----------------------+------------------+-------------------+-------------------------+--------------+---------------------+--------------------+--------------+------------------+-----------------+---------------+-----------------+-------------------------+--------------+----------------------+---------------+-----------------------+-----------------------+-----------------+------------------------+---------------+-----------------------+------------------------+--------------------+----------------------+-------------------+-------------------+---------------------+---------------------+----------------+---------------------+---------------------+---------------------+----------------+-----------------+-------------------+---------------+--------------------+--------------------+---------------+-----------------+--------------+--------------+-----------------+----------------+------------------+----------------------+------------------+--------------------+-------------------------+--------------------+---------------+-----------------+-----------------+----------------+---------------+----------------+-----------------+-----------------+--------------------+-----------------+--------------------+--------------+----------------------+-----------------+------------------------+-------------------------+----------------------+------------------+-------------------+--------------------+-------------------+----------------+------------------+-----------------------+---------------------+-----------------+---------------------+---------------------+-------------------------------+-------------------+---------------------+---------------+----------------------+----------------------+-----------------------+---------------------+-----------------+---------------+--------------------+------------------+--------------------+--------------------+----------------+----------------------+--------------+---------------------+------------------+------------------+----------------+-------------------------+-----------------+-----------------+------------------+-----------------+-----------------+----------------+---------------------+--------------+--------------------+-----------------------+-------------+------------------+--------------------+---------------------------+-----------------------+-------------------+---------------------+-----------------+-----------------+--------------------+--------------------+------------------+------------------+---------------------+------------------+-------------------+------------------+-------------------+------------------+-----------------------+----------------+----------------+------------------+----------------+--------------------+-----------------+---------------+--------------------+---------------+-----------------------+-----------------+-----------------------+---------------+-------------------------+-------------------------+--------------+-----------------------+---------------+--------------+--------------------+-------------------+--------------------+------------------+--------------------+-----------------+--------------------+------------------+---------------------------+-----------------+---------------+--------------------------+----------------------+--------------------+----------------------+----------------+-----------------+----------------+----------------------+---------------------+---------------+-----------------+----------------------+------------------+------------------+---------------+---------------------+----------------+---------------+-----------------+------------------+----------------+--------------+------------------+---------------+-----------------+--------------------+-----------------+----------------+---------------+------------------+-------------------------+------------------+---------------+-------------+-------------------------+----------------+-----------------------+------------------------+---------------------+--------------------------+----------------+-----------------+------------------+-------------------+---------------+--------------+--------------------+----------------------+-----------------+-----------------------+------------------------+-----------------+----------------------+----------------+---------------+----------------------+-------------+----------------------------+---------------------+-----------------+-----------------------------+--------------------+-----------------+------------------+-----------------------+----------------+-------------+----------------------+---------------+-------------------+-------------------+--------------------+----------------------------+---------------+---------------------------+--------------------+------------------+------------------+-------------------+----------------+-----------------+-------------------+---------------+-----------------+-----------------+------------------+------------------+--------------------+------------------+--------------------+-----------------+----------------+----------------+-----------------+-------------------+--------------------+-----------------+-------------------+---------------------------+------------------------+----------------------+----------------+----------------------------+---------------------+-----------------------+---------------+-----------------+-----------------------+-------------------+----------------------+----------------------+-----------------+---------------------+-------------------+-----------------+---------------+---------------+-----------------+-----------------+---------------------+-------------------------+----------------+------------------+------------------------+-----------------+----------------+----------------+------------------+-----------------+---------------+-------------------+------------------+--------------------+-----------------+-----------------+-------------------+--------------+-----------------+---------------------+---------------+-------------------------+----------------------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- street: long (nullable = true)\n",
      " |-- image_id: integer (nullable = true)\n",
      " |-- n_citi: integer (nullable = true)\n",
      " |-- bed: integer (nullable = true)\n",
      " |-- bath: integer (nullable = true)\n",
      " |-- sqft: integer (nullable = true)\n",
      " |-- citi_Mojave, CA: integer (nullable = false)\n",
      " |-- citi_Gorman, CA: integer (nullable = false)\n",
      " |-- citi_Ontario, CA: integer (nullable = false)\n",
      " |-- citi_Creston, CA: integer (nullable = false)\n",
      " |-- citi_Rancho Mirage, CA: integer (nullable = false)\n",
      " |-- citi_Stevenson Ranch, CA: integer (nullable = false)\n",
      " |-- citi_Hemet, CA: integer (nullable = false)\n",
      " |-- citi_Palm Springs, CA: integer (nullable = false)\n",
      " |-- citi_Santa Paula, CA: integer (nullable = false)\n",
      " |-- citi_Altadena, CA: integer (nullable = false)\n",
      " |-- citi_Bell Gardens, CA: integer (nullable = false)\n",
      " |-- citi_La Habra, CA: integer (nullable = false)\n",
      " |-- citi_La Crescenta, CA: integer (nullable = false)\n",
      " |-- citi_Salton City, CA: integer (nullable = false)\n",
      " |-- citi_Los Feliz, CA: integer (nullable = false)\n",
      " |-- citi_West Hollywood, CA: integer (nullable = false)\n",
      " |-- citi_Costa Mesa, CA: integer (nullable = false)\n",
      " |-- citi_Wofford Heights, CA: integer (nullable = false)\n",
      " |-- citi_Montebello, CA: integer (nullable = false)\n",
      " |-- citi_Rimforest, CA: integer (nullable = false)\n",
      " |-- citi_North Tustin, CA: integer (nullable = false)\n",
      " |-- citi_North Hollywood, CA: integer (nullable = false)\n",
      " |-- citi_Compton, CA: integer (nullable = false)\n",
      " |-- citi_Saugus, CA: integer (nullable = false)\n",
      " |-- citi_Barstow, CA: integer (nullable = false)\n",
      " |-- citi_South Gate, CA: integer (nullable = false)\n",
      " |-- citi_Loma Linda, CA: integer (nullable = false)\n",
      " |-- citi_Lemon Grove, CA: integer (nullable = false)\n",
      " |-- citi_Fountain Valley, CA: integer (nullable = false)\n",
      " |-- citi_Cedar Glen, CA: integer (nullable = false)\n",
      " |-- citi_Jamul, CA: integer (nullable = false)\n",
      " |-- citi_Bonsall, CA: integer (nullable = false)\n",
      " |-- citi_Hawthorne, CA: integer (nullable = false)\n",
      " |-- citi_San Fernando, CA: integer (nullable = false)\n",
      " |-- citi_Seal Beach, CA: integer (nullable = false)\n",
      " |-- citi_Big Bear, CA: integer (nullable = false)\n",
      " |-- citi_San Dimas, CA: integer (nullable = false)\n",
      " |-- citi_Cerritos, CA: integer (nullable = false)\n",
      " |-- citi_Aguanga, CA: integer (nullable = false)\n",
      " |-- citi_Bakersfield, CA: integer (nullable = false)\n",
      " |-- citi_Walnut, CA: integer (nullable = false)\n",
      " |-- citi_Pasadena, CA: integer (nullable = false)\n",
      " |-- citi_Anaheim Hills, CA: integer (nullable = false)\n",
      " |-- citi_Oro Grande, CA: integer (nullable = false)\n",
      " |-- citi_Santa Ysabel, CA: integer (nullable = false)\n",
      " |-- citi_Lake Los Angeles, CA: integer (nullable = false)\n",
      " |-- citi_Needles, CA: integer (nullable = false)\n",
      " |-- citi_La Canada Flintridge, CA: integer (nullable = false)\n",
      " |-- citi_West Covina, CA: integer (nullable = false)\n",
      " |-- citi_Ocean Beach, CA: integer (nullable = false)\n",
      " |-- citi_Victorville, CA: integer (nullable = false)\n",
      " |-- citi_Studio City, CA: integer (nullable = false)\n",
      " |-- citi_Montecito, CA: integer (nullable = false)\n",
      " |-- citi_Atascadero, CA: integer (nullable = false)\n",
      " |-- citi_Hollywood, CA: integer (nullable = false)\n",
      " |-- citi_Cabazon, CA: integer (nullable = false)\n",
      " |-- citi_Crestline, CA: integer (nullable = false)\n",
      " |-- citi_Parkfield, CA: integer (nullable = false)\n",
      " |-- citi_California City, CA: integer (nullable = false)\n",
      " |-- citi_Silverado, CA: integer (nullable = false)\n",
      " |-- citi_Pine Valley, CA: integer (nullable = false)\n",
      " |-- citi_Lake Sherwood, CA: integer (nullable = false)\n",
      " |-- citi_Port Hueneme, CA: integer (nullable = false)\n",
      " |-- citi_Downey, CA: integer (nullable = false)\n",
      " |-- citi_Laguna Woods, CA: integer (nullable = false)\n",
      " |-- citi_Covina, CA: integer (nullable = false)\n",
      " |-- citi_Stallion Springs, CA: integer (nullable = false)\n",
      " |-- citi_Piru, CA: integer (nullable = false)\n",
      " |-- citi_El Segundo, CA: integer (nullable = false)\n",
      " |-- citi_Mission Hills, CA: integer (nullable = false)\n",
      " |-- citi_Redondo Beach, CA: integer (nullable = false)\n",
      " |-- citi_Upland, CA: integer (nullable = false)\n",
      " |-- citi_Alta Loma, CA: integer (nullable = false)\n",
      " |-- citi_Big Bear City, CA: integer (nullable = false)\n",
      " |-- citi_Canyon Country, CA: integer (nullable = false)\n",
      " |-- citi_Pearblossom, CA: integer (nullable = false)\n",
      " |-- citi_Lawndale, CA: integer (nullable = false)\n",
      " |-- citi_Moorpark, CA: integer (nullable = false)\n",
      " |-- citi_Tarzana, CA: integer (nullable = false)\n",
      " |-- citi_La Puente, CA: integer (nullable = false)\n",
      " |-- citi_Baldwin Park, CA: integer (nullable = false)\n",
      " |-- citi_Ridgecrest, CA: integer (nullable = false)\n",
      " |-- citi_Toluca Lake, CA: integer (nullable = false)\n",
      " |-- citi_Yorba Linda, CA: integer (nullable = false)\n",
      " |-- citi_Homeland, CA: integer (nullable = false)\n",
      " |-- citi_Venice, CA: integer (nullable = false)\n",
      " |-- citi_Modjeska Canyon, CA: integer (nullable = false)\n",
      " |-- citi_Nuevo, CA: integer (nullable = false)\n",
      " |-- citi_Mentone, CA: integer (nullable = false)\n",
      " |-- citi_Sun Valley, CA: integer (nullable = false)\n",
      " |-- citi_La Verne, CA: integer (nullable = false)\n",
      " |-- citi_Fullerton, CA: integer (nullable = false)\n",
      " |-- citi_La Mesa, CA: integer (nullable = false)\n",
      " |-- citi_Jacumba, CA: integer (nullable = false)\n",
      " |-- citi_Temple City, CA: integer (nullable = false)\n",
      " |-- citi_Grover Beach, CA: integer (nullable = false)\n",
      " |-- citi_Cedarpines Park, CA: integer (nullable = false)\n",
      " |-- citi_Valley Center, CA: integer (nullable = false)\n",
      " |-- citi_Shandon, CA: integer (nullable = false)\n",
      " |-- citi_Monrovia, CA: integer (nullable = false)\n",
      " |-- citi_Campo, CA: integer (nullable = false)\n",
      " |-- citi_Cherry Valley, CA: integer (nullable = false)\n",
      " |-- citi_Spring Valley, CA: integer (nullable = false)\n",
      " |-- citi_Mountain Center, CA: integer (nullable = false)\n",
      " |-- citi_Thermal, CA: integer (nullable = false)\n",
      " |-- citi_Los Alamitos, CA: integer (nullable = false)\n",
      " |-- citi_Rancho Bernardo, CA: integer (nullable = false)\n",
      " |-- citi_Hermosa Beach, CA: integer (nullable = false)\n",
      " |-- citi_South El Monte, CA: integer (nullable = false)\n",
      " |-- citi_Moreno Valley, CA: integer (nullable = false)\n",
      " |-- citi_Brawley, CA: integer (nullable = false)\n",
      " |-- citi_Joshua Tree, CA: integer (nullable = false)\n",
      " |-- citi_Pacific Beach, CA: integer (nullable = false)\n",
      " |-- citi_Templeton, CA: integer (nullable = false)\n",
      " |-- citi_Eagle Rock, CA: integer (nullable = false)\n",
      " |-- citi_Hacienda Heights, CA: integer (nullable = false)\n",
      " |-- citi_Norco, CA: integer (nullable = false)\n",
      " |-- citi_Apple Valley, CA: integer (nullable = false)\n",
      " |-- citi_Carpinteria, CA: integer (nullable = false)\n",
      " |-- citi_Acton, CA: integer (nullable = false)\n",
      " |-- citi_La Mirada, CA: integer (nullable = false)\n",
      " |-- citi_Murrieta, CA: integer (nullable = false)\n",
      " |-- citi_Phelan, CA: integer (nullable = false)\n",
      " |-- citi_Calexico, CA: integer (nullable = false)\n",
      " |-- citi_Santa Fe Springs, CA: integer (nullable = false)\n",
      " |-- citi_Chino, CA: integer (nullable = false)\n",
      " |-- citi_Santa Clarita, CA: integer (nullable = false)\n",
      " |-- citi_Blythe, CA: integer (nullable = false)\n",
      " |-- citi_Lucerne Valley, CA: integer (nullable = false)\n",
      " |-- citi_Warner Springs, CA: integer (nullable = false)\n",
      " |-- citi_Belltown, CA: integer (nullable = false)\n",
      " |-- citi_Rancho Santa Fe, CA: integer (nullable = false)\n",
      " |-- citi_Nipomo, CA: integer (nullable = false)\n",
      " |-- citi_Lake Elizabeth, CA: integer (nullable = false)\n",
      " |-- citi_Huntington Park, CA: integer (nullable = false)\n",
      " |-- citi_Pico Rivera, CA: integer (nullable = false)\n",
      " |-- citi_Highland Park, CA: integer (nullable = false)\n",
      " |-- citi_Whitewater, CA: integer (nullable = false)\n",
      " |-- citi_New Cuyama, CA: integer (nullable = false)\n",
      " |-- citi_Porter Ranch, CA: integer (nullable = false)\n",
      " |-- citi_Shadow Hills, CA: integer (nullable = false)\n",
      " |-- citi_Norwalk, CA: integer (nullable = false)\n",
      " |-- citi_Yucca Valley, CA: integer (nullable = false)\n",
      " |-- citi_Forest Falls, CA: integer (nullable = false)\n",
      " |-- citi_Solana Beach, CA: integer (nullable = false)\n",
      " |-- citi_Cayucos, CA: integer (nullable = false)\n",
      " |-- citi_Lakewood, CA: integer (nullable = false)\n",
      " |-- citi_Wrightwood, CA: integer (nullable = false)\n",
      " |-- citi_Encino, CA: integer (nullable = false)\n",
      " |-- citi_Los Angeles, CA: integer (nullable = false)\n",
      " |-- citi_North Hills, CA: integer (nullable = false)\n",
      " |-- citi_Corona, CA: integer (nullable = false)\n",
      " |-- citi_Buellton, CA: integer (nullable = false)\n",
      " |-- citi_Somis, CA: integer (nullable = false)\n",
      " |-- citi_Lebec, CA: integer (nullable = false)\n",
      " |-- citi_Carlsbad, CA: integer (nullable = false)\n",
      " |-- citi_Dulzura, CA: integer (nullable = false)\n",
      " |-- citi_Claremont, CA: integer (nullable = false)\n",
      " |-- citi_Lake Elsinore, CA: integer (nullable = false)\n",
      " |-- citi_Camarillo, CA: integer (nullable = false)\n",
      " |-- citi_Valley Glen, CA: integer (nullable = false)\n",
      " |-- citi_Rancho Cucamonga, CA: integer (nullable = false)\n",
      " |-- citi_San Gabriel, CA: integer (nullable = false)\n",
      " |-- citi_Malibu, CA: integer (nullable = false)\n",
      " |-- citi_Palmdale, CA: integer (nullable = false)\n",
      " |-- citi_Calimesa, CA: integer (nullable = false)\n",
      " |-- citi_Lynwood, CA: integer (nullable = false)\n",
      " |-- citi_Ramona, CA: integer (nullable = false)\n",
      " |-- citi_Newhall, CA: integer (nullable = false)\n",
      " |-- citi_Rosamond, CA: integer (nullable = false)\n",
      " |-- citi_Highland, CA: integer (nullable = false)\n",
      " |-- citi_Canyon Lake, CA: integer (nullable = false)\n",
      " |-- citi_Caliente, CA: integer (nullable = false)\n",
      " |-- citi_Diamond Bar, CA: integer (nullable = false)\n",
      " |-- citi_Indio, CA: integer (nullable = false)\n",
      " |-- citi_National City, CA: integer (nullable = false)\n",
      " |-- citi_Torrance, CA: integer (nullable = false)\n",
      " |-- citi_Rowland Heights, CA: integer (nullable = false)\n",
      " |-- citi_Lakeview Terrace, CA: integer (nullable = false)\n",
      " |-- citi_Arroyo Grande, CA: integer (nullable = false)\n",
      " |-- citi_Tehachapi, CA: integer (nullable = false)\n",
      " |-- citi_Littlerock, CA: integer (nullable = false)\n",
      " |-- citi_Westminster, CA: integer (nullable = false)\n",
      " |-- citi_Villa Park, CA: integer (nullable = false)\n",
      " |-- citi_Cypress, CA: integer (nullable = false)\n",
      " |-- citi_San Diego, CA: integer (nullable = false)\n",
      " |-- citi_South Pasadena, CA: integer (nullable = false)\n",
      " |-- citi_Leona Valley, CA: integer (nullable = false)\n",
      " |-- citi_Rosemead, CA: integer (nullable = false)\n",
      " |-- citi_Newbury Park, CA: integer (nullable = false)\n",
      " |-- citi_Frazier Park, CA: integer (nullable = false)\n",
      " |-- citi_Rancho Santa Margarita, CA: integer (nullable = false)\n",
      " |-- citi_San Marcos, CA: integer (nullable = false)\n",
      " |-- citi_Green Valley, CA: integer (nullable = false)\n",
      " |-- citi_Carson, CA: integer (nullable = false)\n",
      " |-- citi_Newport Coast, CA: integer (nullable = false)\n",
      " |-- citi_Grand Terrace, CA: integer (nullable = false)\n",
      " |-- citi_Valley Village, CA: integer (nullable = false)\n",
      " |-- citi_Laguna Hills, CA: integer (nullable = false)\n",
      " |-- citi_Winnetka, CA: integer (nullable = false)\n",
      " |-- citi_Tustin, CA: integer (nullable = false)\n",
      " |-- citi_Pinon Hills, CA: integer (nullable = false)\n",
      " |-- citi_Oceanside, CA: integer (nullable = false)\n",
      " |-- citi_Palm Desert, CA: integer (nullable = false)\n",
      " |-- citi_Paso Robles, CA: integer (nullable = false)\n",
      " |-- citi_Tujunga, CA: integer (nullable = false)\n",
      " |-- citi_Mission Viejo, CA: integer (nullable = false)\n",
      " |-- citi_Arvin, CA: integer (nullable = false)\n",
      " |-- citi_Santa Monica, CA: integer (nullable = false)\n",
      " |-- citi_Idyllwild, CA: integer (nullable = false)\n",
      " |-- citi_Boulevard, CA: integer (nullable = false)\n",
      " |-- citi_Potrero, CA: integer (nullable = false)\n",
      " |-- citi_Newberry Springs, CA: integer (nullable = false)\n",
      " |-- citi_Oak Glen, CA: integer (nullable = false)\n",
      " |-- citi_Blue Jay, CA: integer (nullable = false)\n",
      " |-- citi_Oak Hills, CA: integer (nullable = false)\n",
      " |-- citi_Van Nuys, CA: integer (nullable = false)\n",
      " |-- citi_Wildomar, CA: integer (nullable = false)\n",
      " |-- citi_Solvang, CA: integer (nullable = false)\n",
      " |-- citi_Sierra Madre, CA: integer (nullable = false)\n",
      " |-- citi_Poway, CA: integer (nullable = false)\n",
      " |-- citi_Lake Hughes, CA: integer (nullable = false)\n",
      " |-- citi_Phillips Ranch, CA: integer (nullable = false)\n",
      " |-- citi_Brea, CA: integer (nullable = false)\n",
      " |-- citi_San Pedro, CA: integer (nullable = false)\n",
      " |-- citi_Pismo Beach, CA: integer (nullable = false)\n",
      " |-- citi_Vandenberg Village, CA: integer (nullable = false)\n",
      " |-- citi_Woodland Hills, CA: integer (nullable = false)\n",
      " |-- citi_San Marino, CA: integer (nullable = false)\n",
      " |-- citi_Indian Wells, CA: integer (nullable = false)\n",
      " |-- citi_Lakeside, CA: integer (nullable = false)\n",
      " |-- citi_Fillmore, CA: integer (nullable = false)\n",
      " |-- citi_San Jacinto, CA: integer (nullable = false)\n",
      " |-- citi_Lake Forest, CA: integer (nullable = false)\n",
      " |-- citi_Coachella, CA: integer (nullable = false)\n",
      " |-- citi_Morro Bay, CA: integer (nullable = false)\n",
      " |-- citi_Garden Grove, CA: integer (nullable = false)\n",
      " |-- citi_Placentia, CA: integer (nullable = false)\n",
      " |-- citi_Los Alamos, CA: integer (nullable = false)\n",
      " |-- citi_El Mirage, CA: integer (nullable = false)\n",
      " |-- citi_Santa Ynez, CA: integer (nullable = false)\n",
      " |-- citi_Kernville, CA: integer (nullable = false)\n",
      " |-- citi_Thousand Palms, CA: integer (nullable = false)\n",
      " |-- citi_Anaheim, CA: integer (nullable = false)\n",
      " |-- citi_Ventura, CA: integer (nullable = false)\n",
      " |-- citi_Riverside, CA: integer (nullable = false)\n",
      " |-- citi_Cardiff, CA: integer (nullable = false)\n",
      " |-- citi_Santa Maria, CA: integer (nullable = false)\n",
      " |-- citi_La Palma, CA: integer (nullable = false)\n",
      " |-- citi_Oxnard, CA: integer (nullable = false)\n",
      " |-- citi_Quartz Hill, CA: integer (nullable = false)\n",
      " |-- citi_Arleta, CA: integer (nullable = false)\n",
      " |-- citi_Paradise Hills, CA: integer (nullable = false)\n",
      " |-- citi_Los Osos, CA: integer (nullable = false)\n",
      " |-- citi_Corona del Mar, CA: integer (nullable = false)\n",
      " |-- citi_Irvine, CA: integer (nullable = false)\n",
      " |-- citi_Palomar Mountain, CA: integer (nullable = false)\n",
      " |-- citi_Westlake Village, CA: integer (nullable = false)\n",
      " |-- citi_Azusa, CA: integer (nullable = false)\n",
      " |-- citi_San Bernardino, CA: integer (nullable = false)\n",
      " |-- citi_Delano, CA: integer (nullable = false)\n",
      " |-- citi_Llano, CA: integer (nullable = false)\n",
      " |-- citi_Canoga Park, CA: integer (nullable = false)\n",
      " |-- citi_Wilmington, CA: integer (nullable = false)\n",
      " |-- citi_Lake Balboa, CA: integer (nullable = false)\n",
      " |-- citi_Sugarloaf, CA: integer (nullable = false)\n",
      " |-- citi_Simi Valley, CA: integer (nullable = false)\n",
      " |-- citi_El Monte, CA: integer (nullable = false)\n",
      " |-- citi_Pioneertown, CA: integer (nullable = false)\n",
      " |-- citi_Big River, CA: integer (nullable = false)\n",
      " |-- citi_Cardiff by the Sea, CA: integer (nullable = false)\n",
      " |-- citi_Glendale, CA: integer (nullable = false)\n",
      " |-- citi_Duarte, CA: integer (nullable = false)\n",
      " |-- citi_Green Valley Lake, CA: integer (nullable = false)\n",
      " |-- citi_Monterey Park, CA: integer (nullable = false)\n",
      " |-- citi_Harbor City, CA: integer (nullable = false)\n",
      " |-- citi_Santa Barbara, CA: integer (nullable = false)\n",
      " |-- citi_Banning, CA: integer (nullable = false)\n",
      " |-- citi_Redlands, CA: integer (nullable = false)\n",
      " |-- citi_Arcadia, CA: integer (nullable = false)\n",
      " |-- citi_Bermuda Dunes, CA: integer (nullable = false)\n",
      " |-- citi_Angelus Oaks, CA: integer (nullable = false)\n",
      " |-- citi_Bonita, CA: integer (nullable = false)\n",
      " |-- citi_Glendora, CA: integer (nullable = false)\n",
      " |-- citi_Panorama City, CA: integer (nullable = false)\n",
      " |-- citi_Guadalupe, CA: integer (nullable = false)\n",
      " |-- citi_Helendale, CA: integer (nullable = false)\n",
      " |-- citi_Cuyama, CA: integer (nullable = false)\n",
      " |-- citi_Coto de Caza, CA: integer (nullable = false)\n",
      " |-- citi_Pacoima, CA: integer (nullable = false)\n",
      " |-- citi_Oceano, CA: integer (nullable = false)\n",
      " |-- citi_Oak Park, CA: integer (nullable = false)\n",
      " |-- citi_Val Verde, CA: integer (nullable = false)\n",
      " |-- citi_Fontana, CA: integer (nullable = false)\n",
      " |-- citi_Vista, CA: integer (nullable = false)\n",
      " |-- citi_View Park, CA: integer (nullable = false)\n",
      " |-- citi_Perris, CA: integer (nullable = false)\n",
      " |-- citi_Descanso, CA: integer (nullable = false)\n",
      " |-- citi_La Conchita, CA: integer (nullable = false)\n",
      " |-- citi_Hesperia, CA: integer (nullable = false)\n",
      " |-- citi_Del Mar, CA: integer (nullable = false)\n",
      " |-- citi_Santee, CA: integer (nullable = false)\n",
      " |-- citi_Inglewood, CA: integer (nullable = false)\n",
      " |-- citi_East Los Angeles, CA: integer (nullable = false)\n",
      " |-- citi_Calabasas, CA: integer (nullable = false)\n",
      " |-- citi_Orange, CA: integer (nullable = false)\n",
      " |-- citi_Anza, CA: integer (nullable = false)\n",
      " |-- citi_Hawaiian Gardens, CA: integer (nullable = false)\n",
      " |-- citi_Artesia, CA: integer (nullable = false)\n",
      " |-- citi_Morongo Valley, CA: integer (nullable = false)\n",
      " |-- citi_Santa Margarita, CA: integer (nullable = false)\n",
      " |-- citi_Agoura Hills, CA: integer (nullable = false)\n",
      " |-- citi_Pacific Palisades, CA: integer (nullable = false)\n",
      " |-- citi_Menifee, CA: integer (nullable = false)\n",
      " |-- citi_Sun City, CA: integer (nullable = false)\n",
      " |-- citi_Mira Loma, CA: integer (nullable = false)\n",
      " |-- citi_Twin Peaks, CA: integer (nullable = false)\n",
      " |-- citi_Lompoc, CA: integer (nullable = false)\n",
      " |-- citi_Boron, CA: integer (nullable = false)\n",
      " |-- citi_Culver City, CA: integer (nullable = false)\n",
      " |-- citi_Laguna Niguel, CA: integer (nullable = false)\n",
      " |-- citi_Beaumont, CA: integer (nullable = false)\n",
      " |-- citi_Lake Arrowhead, CA: integer (nullable = false)\n",
      " |-- citi_Running Springs, CA: integer (nullable = false)\n",
      " |-- citi_Whittier, CA: integer (nullable = false)\n",
      " |-- citi_Playa del Rey, CA: integer (nullable = false)\n",
      " |-- citi_Topanga, CA: integer (nullable = false)\n",
      " |-- citi_Alpine, CA: integer (nullable = false)\n",
      " |-- citi_Beverly Hills, CA: integer (nullable = false)\n",
      " |-- citi_Bell, CA: integer (nullable = false)\n",
      " |-- citi_San Juan Capistrano, CA: integer (nullable = false)\n",
      " |-- citi_San Clemente, CA: integer (nullable = false)\n",
      " |-- citi_La Jolla, CA: integer (nullable = false)\n",
      " |-- citi_Palos Verdes Estates, CA: integer (nullable = false)\n",
      " |-- citi_Bloomington, CA: integer (nullable = false)\n",
      " |-- citi_El Cajon, CA: integer (nullable = false)\n",
      " |-- citi_Encinitas, CA: integer (nullable = false)\n",
      " |-- citi_Cathedral City, CA: integer (nullable = false)\n",
      " |-- citi_Yucaipa, CA: integer (nullable = false)\n",
      " |-- citi_Ojai, CA: integer (nullable = false)\n",
      " |-- citi_Newport Beach, CA: integer (nullable = false)\n",
      " |-- citi_Rialto, CA: integer (nullable = false)\n",
      " |-- citi_Long Beach, CA: integer (nullable = false)\n",
      " |-- citi_Chatsworth, CA: integer (nullable = false)\n",
      " |-- citi_Avila Beach, CA: integer (nullable = false)\n",
      " |-- citi_Rancho Palos Verdes, CA: integer (nullable = false)\n",
      " |-- citi_Reseda, CA: integer (nullable = false)\n",
      " |-- citi_Pine Mountain Club, CA: integer (nullable = false)\n",
      " |-- citi_Westchester, CA: integer (nullable = false)\n",
      " |-- citi_Lancaster, CA: integer (nullable = false)\n",
      " |-- citi_Paramount, CA: integer (nullable = false)\n",
      " |-- citi_West Hills, CA: integer (nullable = false)\n",
      " |-- citi_Gardena, CA: integer (nullable = false)\n",
      " |-- citi_Montrose, CA: integer (nullable = false)\n",
      " |-- citi_Winchester, CA: integer (nullable = false)\n",
      " |-- citi_Colton, CA: integer (nullable = false)\n",
      " |-- citi_Imperial, CA: integer (nullable = false)\n",
      " |-- citi_Rossmoor, CA: integer (nullable = false)\n",
      " |-- citi_Santa Ana, CA: integer (nullable = false)\n",
      " |-- citi_Montclair, CA: integer (nullable = false)\n",
      " |-- citi_Chula Vista, CA: integer (nullable = false)\n",
      " |-- citi_Fallbrook, CA: integer (nullable = false)\n",
      " |-- citi_Midway City, CA: integer (nullable = false)\n",
      " |-- citi_Temecula, CA: integer (nullable = false)\n",
      " |-- citi_Cambria, CA: integer (nullable = false)\n",
      " |-- citi_Sunland, CA: integer (nullable = false)\n",
      " |-- citi_Mt Baldy, CA: integer (nullable = false)\n",
      " |-- citi_Buena Park, CA: integer (nullable = false)\n",
      " |-- citi_Aliso Viejo, CA: integer (nullable = false)\n",
      " |-- citi_Ranchita, CA: integer (nullable = false)\n",
      " |-- citi_Dana Point, CA: integer (nullable = false)\n",
      " |-- citi_Desert Hot Springs, CA: integer (nullable = false)\n",
      " |-- citi_Borrego Springs, CA: integer (nullable = false)\n",
      " |-- citi_Thousand Oaks, CA: integer (nullable = false)\n",
      " |-- citi_Stanton, CA: integer (nullable = false)\n",
      " |-- citi_Bear Valley Springs, CA: integer (nullable = false)\n",
      " |-- citi_Sherman Oaks, CA: integer (nullable = false)\n",
      " |-- citi_Trabuco Canyon, CA: integer (nullable = false)\n",
      " |-- citi_Lomita, CA: integer (nullable = false)\n",
      " |-- citi_Adelanto, CA: integer (nullable = false)\n",
      " |-- citi_Imperial Beach, CA: integer (nullable = false)\n",
      " |-- citi_Northridge, CA: integer (nullable = false)\n",
      " |-- citi_Juniper Hills, CA: integer (nullable = false)\n",
      " |-- citi_Granada Hills, CA: integer (nullable = false)\n",
      " |-- citi_Valencia, CA: integer (nullable = false)\n",
      " |-- citi_Pauma Valley, CA: integer (nullable = false)\n",
      " |-- citi_Agua Dulce, CA: integer (nullable = false)\n",
      " |-- citi_Coronado, CA: integer (nullable = false)\n",
      " |-- citi_Julian, CA: integer (nullable = false)\n",
      " |-- citi_Sylmar, CA: integer (nullable = false)\n",
      " |-- citi_Romoland, CA: integer (nullable = false)\n",
      " |-- citi_Commerce, CA: integer (nullable = false)\n",
      " |-- citi_Laguna Beach, CA: integer (nullable = false)\n",
      " |-- citi_La Habra Heights, CA: integer (nullable = false)\n",
      " |-- citi_Landers, CA: integer (nullable = false)\n",
      " |-- citi_Escondido, CA: integer (nullable = false)\n",
      " |-- citi_San Luis Obispo, CA: integer (nullable = false)\n",
      " |-- citi_Oak View, CA: integer (nullable = false)\n",
      " |-- citi_Castaic, CA: integer (nullable = false)\n",
      " |-- citi_Burbank, CA: integer (nullable = false)\n",
      " |-- citi_La Quinta, CA: integer (nullable = false)\n",
      " |-- citi_29 Palms, CA: integer (nullable = false)\n",
      " |-- citi_Pomona, CA: integer (nullable = false)\n",
      " |-- citi_San Miguel, CA: integer (nullable = false)\n",
      " |-- citi_Echo Park, CA: integer (nullable = false)\n",
      " |-- citi_Chino Hills, CA: integer (nullable = false)\n",
      " |-- citi_Fawnskin, CA: integer (nullable = false)\n",
      " |-- citi_Inyokern, CA: integer (nullable = false)\n",
      " |-- citi_Bellflower, CA: integer (nullable = false)\n",
      " |-- citi_Keene, CA: integer (nullable = false)\n",
      " |-- citi_Alhambra, CA: integer (nullable = false)\n",
      " |-- citi_Ladera Ranch, CA: integer (nullable = false)\n",
      " |-- citi_Goleta, CA: integer (nullable = false)\n",
      " |-- citi_Huntington Beach, CA: integer (nullable = false)\n",
      " |-- citi_Big Bear Lake, CA: integer (nullable = false)\n",
      " |-- price: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5, truncate=False)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161e4fc7",
   "metadata": {},
   "source": [
    "#### Tách đặc trưng và nhãn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2f5c506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+---+----+----+---------------+---------------+----------------+----------------+----------------------+------------------------+--------------+---------------------+--------------------+-----------------+---------------------+-----------------+---------------------+--------------------+------------------+-----------------------+-------------------+------------------------+-------------------+------------------+---------------------+------------------------+----------------+---------------+----------------+-------------------+-------------------+--------------------+------------------------+-------------------+--------------+----------------+------------------+---------------------+-------------------+-----------------+------------------+-----------------+----------------+--------------------+---------------+-----------------+----------------------+-------------------+---------------------+-------------------------+----------------+-----------------------------+--------------------+--------------------+--------------------+--------------------+------------------+-------------------+------------------+----------------+------------------+------------------+------------------------+------------------+--------------------+----------------------+---------------------+---------------+---------------------+---------------+-------------------------+-------------+-------------------+----------------------+----------------------+---------------+------------------+----------------------+-----------------------+--------------------+-----------------+-----------------+----------------+------------------+---------------------+-------------------+--------------------+--------------------+-----------------+---------------+------------------------+--------------+----------------+-------------------+-----------------+------------------+----------------+----------------+--------------------+---------------------+------------------------+----------------------+----------------+-----------------+--------------+----------------------+----------------------+------------------------+----------------+---------------------+------------------------+----------------------+-----------------------+----------------------+----------------+--------------------+----------------------+------------------+-------------------+-------------------------+--------------+---------------------+--------------------+--------------+------------------+-----------------+---------------+-----------------+-------------------------+--------------+----------------------+---------------+-----------------------+-----------------------+-----------------+------------------------+---------------+-----------------------+------------------------+--------------------+----------------------+-------------------+-------------------+---------------------+---------------------+----------------+---------------------+---------------------+---------------------+----------------+-----------------+-------------------+---------------+--------------------+--------------------+---------------+-----------------+--------------+--------------+-----------------+----------------+------------------+----------------------+------------------+--------------------+-------------------------+--------------------+---------------+-----------------+-----------------+----------------+---------------+----------------+-----------------+-----------------+--------------------+-----------------+--------------------+--------------+----------------------+-----------------+------------------------+-------------------------+----------------------+------------------+-------------------+--------------------+-------------------+----------------+------------------+-----------------------+---------------------+-----------------+---------------------+---------------------+-------------------------------+-------------------+---------------------+---------------+----------------------+----------------------+-----------------------+---------------------+-----------------+---------------+--------------------+------------------+--------------------+--------------------+----------------+----------------------+--------------+---------------------+------------------+------------------+----------------+-------------------------+-----------------+-----------------+------------------+-----------------+-----------------+----------------+---------------------+--------------+--------------------+-----------------------+-------------+------------------+--------------------+---------------------------+-----------------------+-------------------+---------------------+-----------------+-----------------+--------------------+--------------------+------------------+------------------+---------------------+------------------+-------------------+------------------+-------------------+------------------+-----------------------+----------------+----------------+------------------+----------------+--------------------+-----------------+---------------+--------------------+---------------+-----------------------+-----------------+-----------------------+---------------+-------------------------+-------------------------+--------------+-----------------------+---------------+--------------+--------------------+-------------------+--------------------+------------------+--------------------+-----------------+--------------------+------------------+---------------------------+-----------------+---------------+--------------------------+----------------------+--------------------+----------------------+----------------+-----------------+----------------+----------------------+---------------------+---------------+-----------------+----------------------+------------------+------------------+---------------+---------------------+----------------+---------------+-----------------+------------------+----------------+--------------+------------------+---------------+-----------------+--------------------+-----------------+----------------+---------------+------------------+-------------------------+------------------+---------------+-------------+-------------------------+----------------+-----------------------+------------------------+---------------------+--------------------------+----------------+-----------------+------------------+-------------------+---------------+--------------+--------------------+----------------------+-----------------+-----------------------+------------------------+-----------------+----------------------+----------------+---------------+----------------------+-------------+----------------------------+---------------------+-----------------+-----------------------------+--------------------+-----------------+------------------+-----------------------+----------------+-------------+----------------------+---------------+-------------------+-------------------+--------------------+----------------------------+---------------+---------------------------+--------------------+------------------+------------------+-------------------+----------------+-----------------+-------------------+---------------+-----------------+-----------------+------------------+------------------+--------------------+------------------+--------------------+-----------------+----------------+----------------+-----------------+-------------------+--------------------+-----------------+-------------------+---------------------------+------------------------+----------------------+----------------+----------------------------+---------------------+-----------------------+---------------+-----------------+-----------------------+-------------------+----------------------+----------------------+-----------------+---------------------+-------------------+-----------------+---------------+---------------+-----------------+-----------------+---------------------+-------------------------+----------------+------------------+------------------------+-----------------+----------------+----------------+------------------+-----------------+---------------+-------------------+------------------+--------------------+-----------------+-----------------+-------------------+--------------+-----------------+---------------------+---------------+-------------------------+----------------------+------+---------------------------------------------------------+\n",
      "|street|image_id|n_citi|bed|bath|sqft|citi_Mojave, CA|citi_Gorman, CA|citi_Ontario, CA|citi_Creston, CA|citi_Rancho Mirage, CA|citi_Stevenson Ranch, CA|citi_Hemet, CA|citi_Palm Springs, CA|citi_Santa Paula, CA|citi_Altadena, CA|citi_Bell Gardens, CA|citi_La Habra, CA|citi_La Crescenta, CA|citi_Salton City, CA|citi_Los Feliz, CA|citi_West Hollywood, CA|citi_Costa Mesa, CA|citi_Wofford Heights, CA|citi_Montebello, CA|citi_Rimforest, CA|citi_North Tustin, CA|citi_North Hollywood, CA|citi_Compton, CA|citi_Saugus, CA|citi_Barstow, CA|citi_South Gate, CA|citi_Loma Linda, CA|citi_Lemon Grove, CA|citi_Fountain Valley, CA|citi_Cedar Glen, CA|citi_Jamul, CA|citi_Bonsall, CA|citi_Hawthorne, CA|citi_San Fernando, CA|citi_Seal Beach, CA|citi_Big Bear, CA|citi_San Dimas, CA|citi_Cerritos, CA|citi_Aguanga, CA|citi_Bakersfield, CA|citi_Walnut, CA|citi_Pasadena, CA|citi_Anaheim Hills, CA|citi_Oro Grande, CA|citi_Santa Ysabel, CA|citi_Lake Los Angeles, CA|citi_Needles, CA|citi_La Canada Flintridge, CA|citi_West Covina, CA|citi_Ocean Beach, CA|citi_Victorville, CA|citi_Studio City, CA|citi_Montecito, CA|citi_Atascadero, CA|citi_Hollywood, CA|citi_Cabazon, CA|citi_Crestline, CA|citi_Parkfield, CA|citi_California City, CA|citi_Silverado, CA|citi_Pine Valley, CA|citi_Lake Sherwood, CA|citi_Port Hueneme, CA|citi_Downey, CA|citi_Laguna Woods, CA|citi_Covina, CA|citi_Stallion Springs, CA|citi_Piru, CA|citi_El Segundo, CA|citi_Mission Hills, CA|citi_Redondo Beach, CA|citi_Upland, CA|citi_Alta Loma, CA|citi_Big Bear City, CA|citi_Canyon Country, CA|citi_Pearblossom, CA|citi_Lawndale, CA|citi_Moorpark, CA|citi_Tarzana, CA|citi_La Puente, CA|citi_Baldwin Park, CA|citi_Ridgecrest, CA|citi_Toluca Lake, CA|citi_Yorba Linda, CA|citi_Homeland, CA|citi_Venice, CA|citi_Modjeska Canyon, CA|citi_Nuevo, CA|citi_Mentone, CA|citi_Sun Valley, CA|citi_La Verne, CA|citi_Fullerton, CA|citi_La Mesa, CA|citi_Jacumba, CA|citi_Temple City, CA|citi_Grover Beach, CA|citi_Cedarpines Park, CA|citi_Valley Center, CA|citi_Shandon, CA|citi_Monrovia, CA|citi_Campo, CA|citi_Cherry Valley, CA|citi_Spring Valley, CA|citi_Mountain Center, CA|citi_Thermal, CA|citi_Los Alamitos, CA|citi_Rancho Bernardo, CA|citi_Hermosa Beach, CA|citi_South El Monte, CA|citi_Moreno Valley, CA|citi_Brawley, CA|citi_Joshua Tree, CA|citi_Pacific Beach, CA|citi_Templeton, CA|citi_Eagle Rock, CA|citi_Hacienda Heights, CA|citi_Norco, CA|citi_Apple Valley, CA|citi_Carpinteria, CA|citi_Acton, CA|citi_La Mirada, CA|citi_Murrieta, CA|citi_Phelan, CA|citi_Calexico, CA|citi_Santa Fe Springs, CA|citi_Chino, CA|citi_Santa Clarita, CA|citi_Blythe, CA|citi_Lucerne Valley, CA|citi_Warner Springs, CA|citi_Belltown, CA|citi_Rancho Santa Fe, CA|citi_Nipomo, CA|citi_Lake Elizabeth, CA|citi_Huntington Park, CA|citi_Pico Rivera, CA|citi_Highland Park, CA|citi_Whitewater, CA|citi_New Cuyama, CA|citi_Porter Ranch, CA|citi_Shadow Hills, CA|citi_Norwalk, CA|citi_Yucca Valley, CA|citi_Forest Falls, CA|citi_Solana Beach, CA|citi_Cayucos, CA|citi_Lakewood, CA|citi_Wrightwood, CA|citi_Encino, CA|citi_Los Angeles, CA|citi_North Hills, CA|citi_Corona, CA|citi_Buellton, CA|citi_Somis, CA|citi_Lebec, CA|citi_Carlsbad, CA|citi_Dulzura, CA|citi_Claremont, CA|citi_Lake Elsinore, CA|citi_Camarillo, CA|citi_Valley Glen, CA|citi_Rancho Cucamonga, CA|citi_San Gabriel, CA|citi_Malibu, CA|citi_Palmdale, CA|citi_Calimesa, CA|citi_Lynwood, CA|citi_Ramona, CA|citi_Newhall, CA|citi_Rosamond, CA|citi_Highland, CA|citi_Canyon Lake, CA|citi_Caliente, CA|citi_Diamond Bar, CA|citi_Indio, CA|citi_National City, CA|citi_Torrance, CA|citi_Rowland Heights, CA|citi_Lakeview Terrace, CA|citi_Arroyo Grande, CA|citi_Tehachapi, CA|citi_Littlerock, CA|citi_Westminster, CA|citi_Villa Park, CA|citi_Cypress, CA|citi_San Diego, CA|citi_South Pasadena, CA|citi_Leona Valley, CA|citi_Rosemead, CA|citi_Newbury Park, CA|citi_Frazier Park, CA|citi_Rancho Santa Margarita, CA|citi_San Marcos, CA|citi_Green Valley, CA|citi_Carson, CA|citi_Newport Coast, CA|citi_Grand Terrace, CA|citi_Valley Village, CA|citi_Laguna Hills, CA|citi_Winnetka, CA|citi_Tustin, CA|citi_Pinon Hills, CA|citi_Oceanside, CA|citi_Palm Desert, CA|citi_Paso Robles, CA|citi_Tujunga, CA|citi_Mission Viejo, CA|citi_Arvin, CA|citi_Santa Monica, CA|citi_Idyllwild, CA|citi_Boulevard, CA|citi_Potrero, CA|citi_Newberry Springs, CA|citi_Oak Glen, CA|citi_Blue Jay, CA|citi_Oak Hills, CA|citi_Van Nuys, CA|citi_Wildomar, CA|citi_Solvang, CA|citi_Sierra Madre, CA|citi_Poway, CA|citi_Lake Hughes, CA|citi_Phillips Ranch, CA|citi_Brea, CA|citi_San Pedro, CA|citi_Pismo Beach, CA|citi_Vandenberg Village, CA|citi_Woodland Hills, CA|citi_San Marino, CA|citi_Indian Wells, CA|citi_Lakeside, CA|citi_Fillmore, CA|citi_San Jacinto, CA|citi_Lake Forest, CA|citi_Coachella, CA|citi_Morro Bay, CA|citi_Garden Grove, CA|citi_Placentia, CA|citi_Los Alamos, CA|citi_El Mirage, CA|citi_Santa Ynez, CA|citi_Kernville, CA|citi_Thousand Palms, CA|citi_Anaheim, CA|citi_Ventura, CA|citi_Riverside, CA|citi_Cardiff, CA|citi_Santa Maria, CA|citi_La Palma, CA|citi_Oxnard, CA|citi_Quartz Hill, CA|citi_Arleta, CA|citi_Paradise Hills, CA|citi_Los Osos, CA|citi_Corona del Mar, CA|citi_Irvine, CA|citi_Palomar Mountain, CA|citi_Westlake Village, CA|citi_Azusa, CA|citi_San Bernardino, CA|citi_Delano, CA|citi_Llano, CA|citi_Canoga Park, CA|citi_Wilmington, CA|citi_Lake Balboa, CA|citi_Sugarloaf, CA|citi_Simi Valley, CA|citi_El Monte, CA|citi_Pioneertown, CA|citi_Big River, CA|citi_Cardiff by the Sea, CA|citi_Glendale, CA|citi_Duarte, CA|citi_Green Valley Lake, CA|citi_Monterey Park, CA|citi_Harbor City, CA|citi_Santa Barbara, CA|citi_Banning, CA|citi_Redlands, CA|citi_Arcadia, CA|citi_Bermuda Dunes, CA|citi_Angelus Oaks, CA|citi_Bonita, CA|citi_Glendora, CA|citi_Panorama City, CA|citi_Guadalupe, CA|citi_Helendale, CA|citi_Cuyama, CA|citi_Coto de Caza, CA|citi_Pacoima, CA|citi_Oceano, CA|citi_Oak Park, CA|citi_Val Verde, CA|citi_Fontana, CA|citi_Vista, CA|citi_View Park, CA|citi_Perris, CA|citi_Descanso, CA|citi_La Conchita, CA|citi_Hesperia, CA|citi_Del Mar, CA|citi_Santee, CA|citi_Inglewood, CA|citi_East Los Angeles, CA|citi_Calabasas, CA|citi_Orange, CA|citi_Anza, CA|citi_Hawaiian Gardens, CA|citi_Artesia, CA|citi_Morongo Valley, CA|citi_Santa Margarita, CA|citi_Agoura Hills, CA|citi_Pacific Palisades, CA|citi_Menifee, CA|citi_Sun City, CA|citi_Mira Loma, CA|citi_Twin Peaks, CA|citi_Lompoc, CA|citi_Boron, CA|citi_Culver City, CA|citi_Laguna Niguel, CA|citi_Beaumont, CA|citi_Lake Arrowhead, CA|citi_Running Springs, CA|citi_Whittier, CA|citi_Playa del Rey, CA|citi_Topanga, CA|citi_Alpine, CA|citi_Beverly Hills, CA|citi_Bell, CA|citi_San Juan Capistrano, CA|citi_San Clemente, CA|citi_La Jolla, CA|citi_Palos Verdes Estates, CA|citi_Bloomington, CA|citi_El Cajon, CA|citi_Encinitas, CA|citi_Cathedral City, CA|citi_Yucaipa, CA|citi_Ojai, CA|citi_Newport Beach, CA|citi_Rialto, CA|citi_Long Beach, CA|citi_Chatsworth, CA|citi_Avila Beach, CA|citi_Rancho Palos Verdes, CA|citi_Reseda, CA|citi_Pine Mountain Club, CA|citi_Westchester, CA|citi_Lancaster, CA|citi_Paramount, CA|citi_West Hills, CA|citi_Gardena, CA|citi_Montrose, CA|citi_Winchester, CA|citi_Colton, CA|citi_Imperial, CA|citi_Rossmoor, CA|citi_Santa Ana, CA|citi_Montclair, CA|citi_Chula Vista, CA|citi_Fallbrook, CA|citi_Midway City, CA|citi_Temecula, CA|citi_Cambria, CA|citi_Sunland, CA|citi_Mt Baldy, CA|citi_Buena Park, CA|citi_Aliso Viejo, CA|citi_Ranchita, CA|citi_Dana Point, CA|citi_Desert Hot Springs, CA|citi_Borrego Springs, CA|citi_Thousand Oaks, CA|citi_Stanton, CA|citi_Bear Valley Springs, CA|citi_Sherman Oaks, CA|citi_Trabuco Canyon, CA|citi_Lomita, CA|citi_Adelanto, CA|citi_Imperial Beach, CA|citi_Northridge, CA|citi_Juniper Hills, CA|citi_Granada Hills, CA|citi_Valencia, CA|citi_Pauma Valley, CA|citi_Agua Dulce, CA|citi_Coronado, CA|citi_Julian, CA|citi_Sylmar, CA|citi_Romoland, CA|citi_Commerce, CA|citi_Laguna Beach, CA|citi_La Habra Heights, CA|citi_Landers, CA|citi_Escondido, CA|citi_San Luis Obispo, CA|citi_Oak View, CA|citi_Castaic, CA|citi_Burbank, CA|citi_La Quinta, CA|citi_29 Palms, CA|citi_Pomona, CA|citi_San Miguel, CA|citi_Echo Park, CA|citi_Chino Hills, CA|citi_Fawnskin, CA|citi_Inyokern, CA|citi_Bellflower, CA|citi_Keene, CA|citi_Alhambra, CA|citi_Ladera Ranch, CA|citi_Goleta, CA|citi_Huntington Beach, CA|citi_Big Bear Lake, CA|price |features                                                 |\n",
      "+------+--------+------+---+----+----+---------------+---------------+----------------+----------------+----------------------+------------------------+--------------+---------------------+--------------------+-----------------+---------------------+-----------------+---------------------+--------------------+------------------+-----------------------+-------------------+------------------------+-------------------+------------------+---------------------+------------------------+----------------+---------------+----------------+-------------------+-------------------+--------------------+------------------------+-------------------+--------------+----------------+------------------+---------------------+-------------------+-----------------+------------------+-----------------+----------------+--------------------+---------------+-----------------+----------------------+-------------------+---------------------+-------------------------+----------------+-----------------------------+--------------------+--------------------+--------------------+--------------------+------------------+-------------------+------------------+----------------+------------------+------------------+------------------------+------------------+--------------------+----------------------+---------------------+---------------+---------------------+---------------+-------------------------+-------------+-------------------+----------------------+----------------------+---------------+------------------+----------------------+-----------------------+--------------------+-----------------+-----------------+----------------+------------------+---------------------+-------------------+--------------------+--------------------+-----------------+---------------+------------------------+--------------+----------------+-------------------+-----------------+------------------+----------------+----------------+--------------------+---------------------+------------------------+----------------------+----------------+-----------------+--------------+----------------------+----------------------+------------------------+----------------+---------------------+------------------------+----------------------+-----------------------+----------------------+----------------+--------------------+----------------------+------------------+-------------------+-------------------------+--------------+---------------------+--------------------+--------------+------------------+-----------------+---------------+-----------------+-------------------------+--------------+----------------------+---------------+-----------------------+-----------------------+-----------------+------------------------+---------------+-----------------------+------------------------+--------------------+----------------------+-------------------+-------------------+---------------------+---------------------+----------------+---------------------+---------------------+---------------------+----------------+-----------------+-------------------+---------------+--------------------+--------------------+---------------+-----------------+--------------+--------------+-----------------+----------------+------------------+----------------------+------------------+--------------------+-------------------------+--------------------+---------------+-----------------+-----------------+----------------+---------------+----------------+-----------------+-----------------+--------------------+-----------------+--------------------+--------------+----------------------+-----------------+------------------------+-------------------------+----------------------+------------------+-------------------+--------------------+-------------------+----------------+------------------+-----------------------+---------------------+-----------------+---------------------+---------------------+-------------------------------+-------------------+---------------------+---------------+----------------------+----------------------+-----------------------+---------------------+-----------------+---------------+--------------------+------------------+--------------------+--------------------+----------------+----------------------+--------------+---------------------+------------------+------------------+----------------+-------------------------+-----------------+-----------------+------------------+-----------------+-----------------+----------------+---------------------+--------------+--------------------+-----------------------+-------------+------------------+--------------------+---------------------------+-----------------------+-------------------+---------------------+-----------------+-----------------+--------------------+--------------------+------------------+------------------+---------------------+------------------+-------------------+------------------+-------------------+------------------+-----------------------+----------------+----------------+------------------+----------------+--------------------+-----------------+---------------+--------------------+---------------+-----------------------+-----------------+-----------------------+---------------+-------------------------+-------------------------+--------------+-----------------------+---------------+--------------+--------------------+-------------------+--------------------+------------------+--------------------+-----------------+--------------------+------------------+---------------------------+-----------------+---------------+--------------------------+----------------------+--------------------+----------------------+----------------+-----------------+----------------+----------------------+---------------------+---------------+-----------------+----------------------+------------------+------------------+---------------+---------------------+----------------+---------------+-----------------+------------------+----------------+--------------+------------------+---------------+-----------------+--------------------+-----------------+----------------+---------------+------------------+-------------------------+------------------+---------------+-------------+-------------------------+----------------+-----------------------+------------------------+---------------------+--------------------------+----------------+-----------------+------------------+-------------------+---------------+--------------+--------------------+----------------------+-----------------+-----------------------+------------------------+-----------------+----------------------+----------------+---------------+----------------------+-------------+----------------------------+---------------------+-----------------+-----------------------------+--------------------+-----------------+------------------+-----------------------+----------------+-------------+----------------------+---------------+-------------------+-------------------+--------------------+----------------------------+---------------+---------------------------+--------------------+------------------+------------------+-------------------+----------------+-----------------+-------------------+---------------+-----------------+-----------------+------------------+------------------+--------------------+------------------+--------------------+-----------------+----------------+----------------+-----------------+-------------------+--------------------+-----------------+-------------------+---------------------------+------------------------+----------------------+----------------+----------------------------+---------------------+-----------------------+---------------+-----------------+-----------------------+-------------------+----------------------+----------------------+-----------------+---------------------+-------------------+-----------------+---------------+---------------+-----------------+-----------------+---------------------+-------------------------+----------------+------------------+------------------------+-----------------+----------------+----------------+------------------+-----------------+---------------+-------------------+------------------+--------------------+-----------------+-----------------+-------------------+--------------+-----------------+---------------------+---------------+-------------------------+----------------------+------+---------------------------------------------------------+\n",
      "|1     |1       |48    |3  |2   |713 |0              |0              |0               |0               |0                     |0                       |0             |0                    |0                   |0                |0                    |0                |0                    |0                   |0                 |0                      |0                  |0                       |0                  |0                 |0                    |0                       |0               |0              |0               |0                  |0                  |0                   |0                       |0                  |0             |0               |0                 |0                    |0                  |0                |0                 |0                |0               |0                   |0              |0                |0                     |0                  |0                    |0                        |0               |0                            |0                   |0                   |0                   |0                   |0                 |0                  |0                 |0               |0                 |0                 |0                       |0                 |0                   |0                     |0                    |0              |0                    |0              |0                        |0            |0                  |0                     |0                     |0              |0                 |0                     |0                      |0                   |0                |0                |0               |0                 |0                    |0                  |0                   |0                   |0                |0              |0                       |0             |0               |0                  |0                |0                 |0               |0               |0                   |0                    |0                       |0                     |0               |0                |0             |0                     |0                     |0                       |0               |0                    |0                       |0                     |0                      |0                     |1               |0                   |0                     |0                 |0                  |0                        |0             |0                    |0                   |0             |0                 |0                |0              |0                |0                        |0             |0                     |0              |0                      |0                      |0                |0                       |0              |0                      |0                       |0                   |0                     |0                  |0                  |0                    |0                    |0               |0                    |0                    |0                    |0               |0                |0                  |0              |0                   |0                   |0              |0                |0             |0             |0                |0               |0                 |0                     |0                 |0                   |0                        |0                   |0              |0                |0                |0               |0              |0               |0                |0                |0                   |0                |0                   |0             |0                     |0                |0                       |0                        |0                     |0                 |0                  |0                   |0                  |0               |0                 |0                      |0                    |0                |0                    |0                    |0                              |0                  |0                    |0              |0                     |0                     |0                      |0                    |0                |0              |0                   |0                 |0                   |0                   |0               |0                     |0             |0                    |0                 |0                 |0               |0                        |0                |0                |0                 |0                |0                |0               |0                    |0             |0                   |0                      |0            |0                 |0                   |0                          |0                      |0                  |0                    |0                |0                |0                   |0                   |0                 |0                 |0                    |0                 |0                  |0                 |0                  |0                 |0                      |0               |0               |0                 |0               |0                   |0                |0              |0                   |0              |0                      |0                |0                      |0              |0                        |0                        |0             |0                      |0              |0             |0                   |0                  |0                   |0                 |0                   |0                |0                   |0                 |0                          |0                |0              |0                         |0                     |0                   |0                     |0               |0                |0               |0                     |0                    |0              |0                |0                     |0                 |0                 |0              |0                    |0               |0              |0                |0                 |0               |0             |0                 |0              |0                |0                   |0                |0               |0              |0                 |0                        |0                 |0              |0            |0                        |0               |0                      |0                       |0                    |0                         |0               |0                |0                 |0                  |0              |0             |0                   |0                     |0                |0                      |0                       |0                |0                     |0               |0              |0                     |0            |0                           |0                    |0                |0                            |0                   |0                |0                 |0                      |0               |0            |0                     |0              |0                  |0                  |0                   |0                           |0              |0                          |0                   |0                 |0                 |0                  |0               |0                |0                  |0              |0                |0                |0                 |0                 |0                   |0                 |0                   |0                |0               |0               |0                |0                  |0                   |0                |0                  |0                          |0                       |0                     |0               |0                           |0                    |0                      |0              |0                |0                      |0                  |0                     |0                     |0                |0                    |0                  |0                |0              |0              |0                |0                |0                    |0                        |0               |0                 |0                       |0                |0               |0               |0                 |0                |0              |0                  |0                 |0                   |0                |0                |0                  |0             |0                |0                    |0              |0                        |0                     |228500|(421,[0,1,2,3,4,5,116],[1.0,1.0,48.0,3.0,2.0,713.0,1.0]) |\n",
      "|1     |2       |152   |3  |1   |800 |0              |0              |0               |0               |0                     |0                       |0             |0                    |0                   |0                |0                    |0                |0                    |0                   |0                 |0                      |0                  |0                       |0                  |0                 |0                    |0                       |0               |0              |0               |0                  |0                  |0                   |0                       |0                  |0             |0               |0                 |0                    |0                  |0                |0                 |0                |0               |0                   |0              |0                |0                     |0                  |0                    |0                        |0               |0                            |0                   |0                   |0                   |0                   |0                 |0                  |0                 |0               |0                 |0                 |0                       |0                 |0                   |0                     |0                    |0              |0                    |0              |0                        |0            |0                  |0                     |0                     |0              |0                 |0                     |0                      |0                   |0                |0                |0               |0                 |0                    |0                  |0                   |0                   |0                |0              |0                       |0             |0               |0                  |0                |0                 |0               |0               |0                   |0                    |0                       |0                     |0               |0                |0             |0                     |0                     |0                       |0               |0                    |0                       |0                     |0                      |0                     |0               |0                   |0                     |0                 |0                  |0                        |0             |0                    |0                   |0             |0                 |0                |0              |0                |0                        |0             |0                     |0              |0                      |0                      |0                |0                       |0              |0                      |0                       |0                   |0                     |0                  |0                  |0                    |0                    |0               |0                    |0                    |0                    |0               |0                |0                  |0              |0                   |0                   |0              |0                |0             |0             |0                |0               |0                 |0                     |0                 |0                   |0                        |0                   |0              |0                |0                |0               |0              |0               |0                |0                |0                   |0                |0                   |0             |0                     |0                |0                       |0                        |0                     |0                 |0                  |0                   |0                  |0               |0                 |0                      |0                    |0                |0                    |0                    |0                              |0                  |0                    |0              |0                     |0                     |0                      |0                    |0                |0              |0                   |0                 |0                   |0                   |0               |0                     |0             |0                    |0                 |0                 |0               |0                        |0                |0                |0                 |0                |0                |0               |0                    |0             |0                   |0                      |0            |0                 |0                   |0                          |0                      |0                  |0                    |0                |0                |0                   |0                   |0                 |0                 |0                    |0                 |0                  |0                 |0                  |0                 |0                      |0               |0               |0                 |0               |0                   |0                |0              |0                   |0              |0                      |0                |0                      |0              |0                        |0                        |0             |0                      |0              |0             |0                   |0                  |0                   |0                 |0                   |0                |0                   |0                 |0                          |0                |0              |0                         |0                     |0                   |0                     |0               |0                |0               |0                     |0                    |0              |0                |0                     |0                 |0                 |0              |0                    |0               |0              |0                |0                 |0               |0             |0                 |0              |0                |0                   |0                |0               |0              |0                 |0                        |0                 |0              |0            |0                        |0               |0                      |0                       |0                    |0                         |0               |0                |0                 |0                  |0              |0             |0                   |0                     |0                |0                      |0                       |0                |0                     |0               |0              |0                     |0            |0                           |0                    |0                |0                            |0                   |0                |0                 |0                      |0               |0            |0                     |0              |0                  |0                  |0                   |0                           |0              |0                          |0                   |0                 |0                 |0                  |0               |0                |0                  |0              |1                |0                |0                 |0                 |0                   |0                 |0                   |0                |0               |0               |0                |0                  |0                   |0                |0                  |0                          |0                       |0                     |0               |0                           |0                    |0                      |0              |0                |0                      |0                  |0                     |0                     |0                |0                    |0                  |0                |0              |0              |0                |0                |0                    |0                        |0               |0                 |0                       |0                |0               |0               |0                 |0                |0              |0                  |0                 |0                   |0                |0                |0                  |0             |0                |0                    |0              |0                        |0                     |273950|(421,[0,1,2,3,4,5,362],[1.0,2.0,152.0,3.0,1.0,800.0,1.0])|\n",
      "|1     |3       |48    |3  |1   |1082|0              |0              |0               |0               |0                     |0                       |0             |0                    |0                   |0                |0                    |0                |0                    |0                   |0                 |0                      |0                  |0                       |0                  |0                 |0                    |0                       |0               |0              |0               |0                  |0                  |0                   |0                       |0                  |0             |0               |0                 |0                    |0                  |0                |0                 |0                |0               |0                   |0              |0                |0                     |0                  |0                    |0                        |0               |0                            |0                   |0                   |0                   |0                   |0                 |0                  |0                 |0               |0                 |0                 |0                       |0                 |0                   |0                     |0                    |0              |0                    |0              |0                        |0            |0                  |0                     |0                     |0              |0                 |0                     |0                      |0                   |0                |0                |0               |0                 |0                    |0                  |0                   |0                   |0                |0              |0                       |0             |0               |0                  |0                |0                 |0               |0               |0                   |0                    |0                       |0                     |0               |0                |0             |0                     |0                     |0                       |0               |0                    |0                       |0                     |0                      |0                     |1               |0                   |0                     |0                 |0                  |0                        |0             |0                    |0                   |0             |0                 |0                |0              |0                |0                        |0             |0                     |0              |0                      |0                      |0                |0                       |0              |0                      |0                       |0                   |0                     |0                  |0                  |0                    |0                    |0               |0                    |0                    |0                    |0               |0                |0                  |0              |0                   |0                   |0              |0                |0             |0             |0                |0               |0                 |0                     |0                 |0                   |0                        |0                   |0              |0                |0                |0               |0              |0               |0                |0                |0                   |0                |0                   |0             |0                     |0                |0                       |0                        |0                     |0                 |0                  |0                   |0                  |0               |0                 |0                      |0                    |0                |0                    |0                    |0                              |0                  |0                    |0              |0                     |0                     |0                      |0                    |0                |0              |0                   |0                 |0                   |0                   |0               |0                     |0             |0                    |0                 |0                 |0               |0                        |0                |0                |0                 |0                |0                |0               |0                    |0             |0                   |0                      |0            |0                 |0                   |0                          |0                      |0                  |0                    |0                |0                |0                   |0                   |0                 |0                 |0                    |0                 |0                  |0                 |0                  |0                 |0                      |0               |0               |0                 |0               |0                   |0                |0              |0                   |0              |0                      |0                |0                      |0              |0                        |0                        |0             |0                      |0              |0             |0                   |0                  |0                   |0                 |0                   |0                |0                   |0                 |0                          |0                |0              |0                         |0                     |0                   |0                     |0               |0                |0               |0                     |0                    |0              |0                |0                     |0                 |0                 |0              |0                    |0               |0              |0                |0                 |0               |0             |0                 |0              |0                |0                   |0                |0               |0              |0                 |0                        |0                 |0              |0            |0                        |0               |0                      |0                       |0                    |0                         |0               |0                |0                 |0                  |0              |0             |0                   |0                     |0                |0                      |0                       |0                |0                     |0               |0              |0                     |0            |0                           |0                    |0                |0                            |0                   |0                |0                 |0                      |0               |0            |0                     |0              |0                  |0                  |0                   |0                           |0              |0                          |0                   |0                 |0                 |0                  |0               |0                |0                  |0              |0                |0                |0                 |0                 |0                   |0                 |0                   |0                |0               |0               |0                |0                  |0                   |0                |0                  |0                          |0                       |0                     |0               |0                           |0                    |0                      |0              |0                |0                      |0                  |0                     |0                     |0                |0                    |0                  |0                |0              |0              |0                |0                |0                    |0                        |0               |0                 |0                       |0                |0               |0               |0                 |0                |0              |0                  |0                 |0                   |0                |0                |0                  |0             |0                |0                    |0              |0                        |0                     |350000|(421,[0,1,2,3,4,5,116],[1.0,3.0,48.0,3.0,1.0,1082.0,1.0])|\n",
      "|1     |4       |55    |4  |3   |2547|0              |0              |0               |0               |0                     |0                       |0             |0                    |0                   |0                |0                    |0                |0                    |0                   |0                 |0                      |0                  |0                       |0                  |0                 |0                    |0                       |0               |0              |0               |0                  |0                  |0                   |0                       |0                  |0             |0               |0                 |0                    |0                  |0                |0                 |0                |0               |0                   |0              |0                |0                     |0                  |0                    |0                        |0               |0                            |0                   |0                   |0                   |0                   |0                 |0                  |0                 |0               |0                 |0                 |0                       |0                 |0                   |0                     |0                    |0              |0                    |0              |0                        |0            |0                  |0                     |0                     |0              |0                 |0                     |0                      |0                   |0                |0                |0               |0                 |0                    |0                  |0                   |0                   |0                |0              |0                       |0             |0               |0                  |0                |0                 |0               |0               |0                   |0                    |0                       |0                     |0               |0                |0             |0                     |0                     |0                       |0               |0                    |0                       |0                     |0                      |0                     |0               |0                   |0                     |0                 |0                  |0                        |0             |0                    |0                   |0             |0                 |0                |0              |1                |0                        |0             |0                     |0              |0                      |0                      |0                |0                       |0              |0                      |0                       |0                   |0                     |0                  |0                  |0                    |0                    |0               |0                    |0                    |0                    |0               |0                |0                  |0              |0                   |0                   |0              |0                |0             |0             |0                |0               |0                 |0                     |0                 |0                   |0                        |0                   |0              |0                |0                |0               |0              |0               |0                |0                |0                   |0                |0                   |0             |0                     |0                |0                       |0                        |0                     |0                 |0                  |0                   |0                  |0               |0                 |0                      |0                    |0                |0                    |0                    |0                              |0                  |0                    |0              |0                     |0                     |0                      |0                    |0                |0              |0                   |0                 |0                   |0                   |0               |0                     |0             |0                    |0                 |0                 |0               |0                        |0                |0                |0                 |0                |0                |0               |0                    |0             |0                   |0                      |0            |0                 |0                   |0                          |0                      |0                  |0                    |0                |0                |0                   |0                   |0                 |0                 |0                    |0                 |0                  |0                 |0                  |0                 |0                      |0               |0               |0                 |0               |0                   |0                |0              |0                   |0              |0                      |0                |0                      |0              |0                        |0                        |0             |0                      |0              |0             |0                   |0                  |0                   |0                 |0                   |0                |0                   |0                 |0                          |0                |0              |0                         |0                     |0                   |0                     |0               |0                |0               |0                     |0                    |0              |0                |0                     |0                 |0                 |0              |0                    |0               |0              |0                |0                 |0               |0             |0                 |0              |0                |0                   |0                |0               |0              |0                 |0                        |0                 |0              |0            |0                        |0               |0                      |0                       |0                    |0                         |0               |0                |0                 |0                  |0              |0             |0                   |0                     |0                |0                      |0                       |0                |0                     |0               |0              |0                     |0            |0                           |0                    |0                |0                            |0                   |0                |0                 |0                      |0               |0            |0                     |0              |0                  |0                  |0                   |0                           |0              |0                          |0                   |0                 |0                 |0                  |0               |0                |0                  |0              |0                |0                |0                 |0                 |0                   |0                 |0                   |0                |0               |0               |0                |0                  |0                   |0                |0                  |0                          |0                       |0                     |0               |0                           |0                    |0                      |0              |0                |0                      |0                  |0                     |0                     |0                |0                    |0                  |0                |0              |0              |0                |0                |0                    |0                        |0               |0                 |0                       |0                |0               |0               |0                 |0                |0              |0                  |0                 |0                   |0                |0                |0                  |0             |0                |0                    |0              |0                        |0                     |385100|(421,[0,1,2,3,4,5,129],[1.0,4.0,55.0,4.0,3.0,2547.0,1.0])|\n",
      "|1     |6       |55    |4  |3   |2769|0              |0              |0               |0               |0                     |0                       |0             |0                    |0                   |0                |0                    |0                |0                    |0                   |0                 |0                      |0                  |0                       |0                  |0                 |0                    |0                       |0               |0              |0               |0                  |0                  |0                   |0                       |0                  |0             |0               |0                 |0                    |0                  |0                |0                 |0                |0               |0                   |0              |0                |0                     |0                  |0                    |0                        |0               |0                            |0                   |0                   |0                   |0                   |0                 |0                  |0                 |0               |0                 |0                 |0                       |0                 |0                   |0                     |0                    |0              |0                    |0              |0                        |0            |0                  |0                     |0                     |0              |0                 |0                     |0                      |0                   |0                |0                |0               |0                 |0                    |0                  |0                   |0                   |0                |0              |0                       |0             |0               |0                  |0                |0                 |0               |0               |0                   |0                    |0                       |0                     |0               |0                |0             |0                     |0                     |0                       |0               |0                    |0                       |0                     |0                      |0                     |0               |0                   |0                     |0                 |0                  |0                        |0             |0                    |0                   |0             |0                 |0                |0              |1                |0                        |0             |0                     |0              |0                      |0                      |0                |0                       |0              |0                      |0                       |0                   |0                     |0                  |0                  |0                    |0                    |0               |0                    |0                    |0                    |0               |0                |0                  |0              |0                   |0                   |0              |0                |0             |0             |0                |0               |0                 |0                     |0                 |0                   |0                        |0                   |0              |0                |0                |0               |0              |0               |0                |0                |0                   |0                |0                   |0             |0                     |0                |0                       |0                        |0                     |0                 |0                  |0                   |0                  |0               |0                 |0                      |0                    |0                |0                    |0                    |0                              |0                  |0                    |0              |0                     |0                     |0                      |0                    |0                |0              |0                   |0                 |0                   |0                   |0               |0                     |0             |0                    |0                 |0                 |0               |0                        |0                |0                |0                 |0                |0                |0               |0                    |0             |0                   |0                      |0            |0                 |0                   |0                          |0                      |0                  |0                    |0                |0                |0                   |0                   |0                 |0                 |0                    |0                 |0                  |0                 |0                  |0                 |0                      |0               |0               |0                 |0               |0                   |0                |0              |0                   |0              |0                      |0                |0                      |0              |0                        |0                        |0             |0                      |0              |0             |0                   |0                  |0                   |0                 |0                   |0                |0                   |0                 |0                          |0                |0              |0                         |0                     |0                   |0                     |0               |0                |0               |0                     |0                    |0              |0                |0                     |0                 |0                 |0              |0                    |0               |0              |0                |0                 |0               |0             |0                 |0              |0                |0                   |0                |0               |0              |0                 |0                        |0                 |0              |0            |0                        |0               |0                      |0                       |0                    |0                         |0               |0                |0                 |0                  |0              |0             |0                   |0                     |0                |0                      |0                       |0                |0                     |0               |0              |0                     |0            |0                           |0                    |0                |0                            |0                   |0                |0                 |0                      |0               |0            |0                     |0              |0                  |0                  |0                   |0                           |0              |0                          |0                   |0                 |0                 |0                  |0               |0                |0                  |0              |0                |0                |0                 |0                 |0                   |0                 |0                   |0                |0               |0               |0                |0                  |0                   |0                |0                  |0                          |0                       |0                     |0               |0                           |0                    |0                      |0              |0                |0                      |0                  |0                     |0                     |0                |0                    |0                  |0                |0              |0              |0                |0                |0                    |0                        |0               |0                 |0                       |0                |0               |0               |0                 |0                |0              |0                  |0                 |0                   |0                |0                |0                  |0             |0                |0                    |0              |0                        |0                     |415000|(421,[0,1,2,3,4,5,129],[1.0,6.0,55.0,4.0,3.0,2769.0,1.0])|\n",
      "+------+--------+------+---+----+----+---------------+---------------+----------------+----------------+----------------------+------------------------+--------------+---------------------+--------------------+-----------------+---------------------+-----------------+---------------------+--------------------+------------------+-----------------------+-------------------+------------------------+-------------------+------------------+---------------------+------------------------+----------------+---------------+----------------+-------------------+-------------------+--------------------+------------------------+-------------------+--------------+----------------+------------------+---------------------+-------------------+-----------------+------------------+-----------------+----------------+--------------------+---------------+-----------------+----------------------+-------------------+---------------------+-------------------------+----------------+-----------------------------+--------------------+--------------------+--------------------+--------------------+------------------+-------------------+------------------+----------------+------------------+------------------+------------------------+------------------+--------------------+----------------------+---------------------+---------------+---------------------+---------------+-------------------------+-------------+-------------------+----------------------+----------------------+---------------+------------------+----------------------+-----------------------+--------------------+-----------------+-----------------+----------------+------------------+---------------------+-------------------+--------------------+--------------------+-----------------+---------------+------------------------+--------------+----------------+-------------------+-----------------+------------------+----------------+----------------+--------------------+---------------------+------------------------+----------------------+----------------+-----------------+--------------+----------------------+----------------------+------------------------+----------------+---------------------+------------------------+----------------------+-----------------------+----------------------+----------------+--------------------+----------------------+------------------+-------------------+-------------------------+--------------+---------------------+--------------------+--------------+------------------+-----------------+---------------+-----------------+-------------------------+--------------+----------------------+---------------+-----------------------+-----------------------+-----------------+------------------------+---------------+-----------------------+------------------------+--------------------+----------------------+-------------------+-------------------+---------------------+---------------------+----------------+---------------------+---------------------+---------------------+----------------+-----------------+-------------------+---------------+--------------------+--------------------+---------------+-----------------+--------------+--------------+-----------------+----------------+------------------+----------------------+------------------+--------------------+-------------------------+--------------------+---------------+-----------------+-----------------+----------------+---------------+----------------+-----------------+-----------------+--------------------+-----------------+--------------------+--------------+----------------------+-----------------+------------------------+-------------------------+----------------------+------------------+-------------------+--------------------+-------------------+----------------+------------------+-----------------------+---------------------+-----------------+---------------------+---------------------+-------------------------------+-------------------+---------------------+---------------+----------------------+----------------------+-----------------------+---------------------+-----------------+---------------+--------------------+------------------+--------------------+--------------------+----------------+----------------------+--------------+---------------------+------------------+------------------+----------------+-------------------------+-----------------+-----------------+------------------+-----------------+-----------------+----------------+---------------------+--------------+--------------------+-----------------------+-------------+------------------+--------------------+---------------------------+-----------------------+-------------------+---------------------+-----------------+-----------------+--------------------+--------------------+------------------+------------------+---------------------+------------------+-------------------+------------------+-------------------+------------------+-----------------------+----------------+----------------+------------------+----------------+--------------------+-----------------+---------------+--------------------+---------------+-----------------------+-----------------+-----------------------+---------------+-------------------------+-------------------------+--------------+-----------------------+---------------+--------------+--------------------+-------------------+--------------------+------------------+--------------------+-----------------+--------------------+------------------+---------------------------+-----------------+---------------+--------------------------+----------------------+--------------------+----------------------+----------------+-----------------+----------------+----------------------+---------------------+---------------+-----------------+----------------------+------------------+------------------+---------------+---------------------+----------------+---------------+-----------------+------------------+----------------+--------------+------------------+---------------+-----------------+--------------------+-----------------+----------------+---------------+------------------+-------------------------+------------------+---------------+-------------+-------------------------+----------------+-----------------------+------------------------+---------------------+--------------------------+----------------+-----------------+------------------+-------------------+---------------+--------------+--------------------+----------------------+-----------------+-----------------------+------------------------+-----------------+----------------------+----------------+---------------+----------------------+-------------+----------------------------+---------------------+-----------------+-----------------------------+--------------------+-----------------+------------------+-----------------------+----------------+-------------+----------------------+---------------+-------------------+-------------------+--------------------+----------------------------+---------------+---------------------------+--------------------+------------------+------------------+-------------------+----------------+-----------------+-------------------+---------------+-----------------+-----------------+------------------+------------------+--------------------+------------------+--------------------+-----------------+----------------+----------------+-----------------+-------------------+--------------------+-----------------+-------------------+---------------------------+------------------------+----------------------+----------------+----------------------------+---------------------+-----------------------+---------------+-----------------+-----------------------+-------------------+----------------------+----------------------+-----------------+---------------------+-------------------+-----------------+---------------+---------------+-----------------+-----------------+---------------------+-------------------------+----------------+------------------+------------------------+-----------------+----------------+----------------+------------------+-----------------+---------------+-------------------+------------------+--------------------+-----------------+-----------------+-------------------+--------------+-----------------+---------------------+---------------+-------------------------+----------------------+------+---------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns = df.columns\n",
    "feature_cols = columns[:-1] \n",
    "label_col = columns[-1]  \n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "df_transformed = assembler.transform(df)\n",
    "\n",
    "df_transformed.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8538ed9",
   "metadata": {},
   "source": [
    "### Chia train, valid và test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "822b5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 2. Chia train / valid / test --- \n",
    "train_data, valid_data, test_data = df_transformed.randomSplit([0.7, 0.15, 0.15], seed=42)\n",
    "\n",
    "# --- 3. Hàm đánh giá ---\n",
    "def evaluate(predictions, label_col):\n",
    "    evaluator_rmse = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    evaluator_r2 = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"r2\")\n",
    "    rmse = evaluator_rmse.evaluate(predictions)\n",
    "    r2 = evaluator_r2.evaluate(predictions)\n",
    "    print(f\"RMSE = {rmse:.4f} | R² = {r2:.4f}\")\n",
    "    return rmse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d6d6b8",
   "metadata": {},
   "source": [
    "### 4. Huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03c39e2",
   "metadata": {},
   "source": [
    "#### 4.1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b1b6e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Linear Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/27 07:51:02 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "25/10/27 07:51:02 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "25/10/27 07:51:02 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 208214.4111 | R² = 0.7110\n",
      "Best Parameters:\n",
      "  - regParam: 0.01\n",
      "  - elasticNetParam: 1.0\n",
      "  - maxIter: 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=label_col)\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.01, 0.1, 0.3, 0.5])\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "             .addGrid(lr.maxIter, [100, 300, 500])\n",
    "             .build())\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "crossval = CrossValidator(estimator=lr,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)\n",
    "\n",
    "print(\"\\nTraining Linear Regression...\")\n",
    "cvModel = crossval.fit(train_data)\n",
    "\n",
    "bestModel_lr = cvModel.bestModel\n",
    "\n",
    "pred_lr = bestModel_lr.transform(valid_data)\n",
    "\n",
    "evaluate(pred_lr, label_col)\n",
    "\n",
    "print(f\"Best Parameters:\")\n",
    "print(f\"  - regParam: {bestModel_lr._java_obj.getRegParam()}\")\n",
    "print(f\"  - elasticNetParam: {bestModel_lr._java_obj.getElasticNetParam()}\")\n",
    "print(f\"  - maxIter: {bestModel_lr._java_obj.getMaxIter()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9794f529",
   "metadata": {},
   "source": [
    "#### 4.2. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef032a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Decision Tree...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/27 07:56:24 WARN DAGScheduler: Broadcasting large task binary with size 1024.9 KiB\n",
      "25/10/27 07:56:24 WARN DAGScheduler: Broadcasting large task binary with size 1115.9 KiB\n",
      "25/10/27 07:56:24 WARN DAGScheduler: Broadcasting large task binary with size 1206.2 KiB\n",
      "25/10/27 07:56:24 WARN DAGScheduler: Broadcasting large task binary with size 1290.5 KiB\n",
      "25/10/27 07:56:25 WARN DAGScheduler: Broadcasting large task binary with size 1365.9 KiB\n",
      "25/10/27 07:56:25 WARN DAGScheduler: Broadcasting large task binary with size 1014.0 KiB\n",
      "25/10/27 07:56:26 WARN DAGScheduler: Broadcasting large task binary with size 1024.9 KiB\n",
      "25/10/27 07:56:26 WARN DAGScheduler: Broadcasting large task binary with size 1115.8 KiB\n",
      "25/10/27 07:56:27 WARN DAGScheduler: Broadcasting large task binary with size 1206.1 KiB\n",
      "25/10/27 07:56:27 WARN DAGScheduler: Broadcasting large task binary with size 1290.4 KiB\n",
      "25/10/27 07:56:27 WARN DAGScheduler: Broadcasting large task binary with size 1365.9 KiB\n",
      "25/10/27 07:56:28 WARN DAGScheduler: Broadcasting large task binary with size 1014.0 KiB\n",
      "25/10/27 07:56:28 WARN DAGScheduler: Broadcasting large task binary with size 1024.9 KiB\n",
      "25/10/27 07:56:28 WARN DAGScheduler: Broadcasting large task binary with size 1115.8 KiB\n",
      "25/10/27 07:56:28 WARN DAGScheduler: Broadcasting large task binary with size 1206.1 KiB\n",
      "25/10/27 07:56:28 WARN DAGScheduler: Broadcasting large task binary with size 1290.4 KiB\n",
      "25/10/27 07:56:28 WARN DAGScheduler: Broadcasting large task binary with size 1365.9 KiB\n",
      "25/10/27 07:56:29 WARN DAGScheduler: Broadcasting large task binary with size 1014.0 KiB\n",
      "25/10/27 07:56:30 WARN DAGScheduler: Broadcasting large task binary with size 1036.7 KiB\n",
      "25/10/27 07:56:30 WARN DAGScheduler: Broadcasting large task binary with size 1072.0 KiB\n",
      "25/10/27 07:56:31 WARN DAGScheduler: Broadcasting large task binary with size 1036.7 KiB\n",
      "25/10/27 07:56:31 WARN DAGScheduler: Broadcasting large task binary with size 1071.9 KiB\n",
      "25/10/27 07:56:33 WARN DAGScheduler: Broadcasting large task binary with size 1036.7 KiB\n",
      "25/10/27 07:56:33 WARN DAGScheduler: Broadcasting large task binary with size 1071.9 KiB\n",
      "25/10/27 07:57:31 WARN DAGScheduler: Broadcasting large task binary with size 1054.7 KiB\n",
      "25/10/27 07:57:31 WARN DAGScheduler: Broadcasting large task binary with size 1142.3 KiB\n",
      "25/10/27 07:57:31 WARN DAGScheduler: Broadcasting large task binary with size 1228.3 KiB\n",
      "25/10/27 07:57:32 WARN DAGScheduler: Broadcasting large task binary with size 1308.4 KiB\n",
      "25/10/27 07:57:34 WARN DAGScheduler: Broadcasting large task binary with size 1054.7 KiB\n",
      "25/10/27 07:57:34 WARN DAGScheduler: Broadcasting large task binary with size 1142.3 KiB\n",
      "25/10/27 07:57:34 WARN DAGScheduler: Broadcasting large task binary with size 1228.3 KiB\n",
      "25/10/27 07:57:34 WARN DAGScheduler: Broadcasting large task binary with size 1308.4 KiB\n",
      "25/10/27 07:57:35 WARN DAGScheduler: Broadcasting large task binary with size 1054.7 KiB\n",
      "25/10/27 07:57:35 WARN DAGScheduler: Broadcasting large task binary with size 1142.3 KiB\n",
      "25/10/27 07:57:35 WARN DAGScheduler: Broadcasting large task binary with size 1228.3 KiB\n",
      "25/10/27 07:57:36 WARN DAGScheduler: Broadcasting large task binary with size 1308.4 KiB\n",
      "25/10/27 07:57:38 WARN DAGScheduler: Broadcasting large task binary with size 1004.5 KiB\n",
      "25/10/27 07:57:38 WARN DAGScheduler: Broadcasting large task binary with size 1051.7 KiB\n",
      "25/10/27 07:57:38 WARN DAGScheduler: Broadcasting large task binary with size 1089.9 KiB\n",
      "25/10/27 07:57:39 WARN DAGScheduler: Broadcasting large task binary with size 1004.5 KiB\n",
      "25/10/27 07:57:39 WARN DAGScheduler: Broadcasting large task binary with size 1051.7 KiB\n",
      "25/10/27 07:57:39 WARN DAGScheduler: Broadcasting large task binary with size 1089.9 KiB\n",
      "25/10/27 07:57:41 WARN DAGScheduler: Broadcasting large task binary with size 1004.5 KiB\n",
      "25/10/27 07:57:42 WARN DAGScheduler: Broadcasting large task binary with size 1051.7 KiB\n",
      "25/10/27 07:57:42 WARN DAGScheduler: Broadcasting large task binary with size 1089.9 KiB\n",
      "25/10/27 07:58:41 WARN DAGScheduler: Broadcasting large task binary with size 1052.8 KiB\n",
      "25/10/27 07:58:41 WARN DAGScheduler: Broadcasting large task binary with size 1136.1 KiB\n",
      "25/10/27 07:58:41 WARN DAGScheduler: Broadcasting large task binary with size 1216.3 KiB\n",
      "25/10/27 07:58:41 WARN DAGScheduler: Broadcasting large task binary with size 1290.3 KiB\n",
      "25/10/27 07:58:43 WARN DAGScheduler: Broadcasting large task binary with size 1052.8 KiB\n",
      "25/10/27 07:58:43 WARN DAGScheduler: Broadcasting large task binary with size 1136.1 KiB\n",
      "25/10/27 07:58:44 WARN DAGScheduler: Broadcasting large task binary with size 1216.3 KiB\n",
      "25/10/27 07:58:44 WARN DAGScheduler: Broadcasting large task binary with size 1290.3 KiB\n",
      "25/10/27 07:58:44 WARN DAGScheduler: Broadcasting large task binary with size 1052.8 KiB\n",
      "25/10/27 07:58:44 WARN DAGScheduler: Broadcasting large task binary with size 1136.1 KiB\n",
      "25/10/27 07:58:45 WARN DAGScheduler: Broadcasting large task binary with size 1216.3 KiB\n",
      "25/10/27 07:58:45 WARN DAGScheduler: Broadcasting large task binary with size 1290.3 KiB\n",
      "25/10/27 07:58:47 WARN DAGScheduler: Broadcasting large task binary with size 1005.6 KiB\n",
      "25/10/27 07:58:47 WARN DAGScheduler: Broadcasting large task binary with size 1048.2 KiB\n",
      "25/10/27 07:58:48 WARN DAGScheduler: Broadcasting large task binary with size 1005.6 KiB\n",
      "25/10/27 07:58:48 WARN DAGScheduler: Broadcasting large task binary with size 1048.2 KiB\n",
      "25/10/27 07:58:50 WARN DAGScheduler: Broadcasting large task binary with size 1005.6 KiB\n",
      "25/10/27 07:58:50 WARN DAGScheduler: Broadcasting large task binary with size 1048.2 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 191144.2677 | R² = 0.7564\n",
      "Best Parameters:\n",
      "  - maxDepth: 15\n",
      "  - minInstancesPerNode: 4\n",
      "  - minInfoGain: 0.0\n",
      "RMSE: 191144.2677\n",
      "R²: 0.7564\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nTraining Decision Tree...\")\n",
    "\n",
    "dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=label_col)\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(dt.maxDepth, [5, 10, 15, 20])\n",
    "             .addGrid(dt.minInstancesPerNode, [1, 2, 4])\n",
    "             .addGrid(dt.minInfoGain, [0.0, 0.01, 0.05])\n",
    "             .build())\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "crossval = CrossValidator(estimator=dt,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3,    \n",
    "                          parallelism=2)  \n",
    "\n",
    "cvModel = crossval.fit(train_data)\n",
    "bestModel_dt = cvModel.bestModel\n",
    "\n",
    "pred_dt = bestModel_dt.transform(valid_data)\n",
    "\n",
    "dt_rmse, dt_r2 = evaluate(pred_dt, label_col)\n",
    "\n",
    "print(f\"Best Parameters:\")\n",
    "print(f\"  - maxDepth: {bestModel_dt.getMaxDepth()}\")\n",
    "print(f\"  - minInstancesPerNode: {bestModel_dt.getMinInstancesPerNode()}\")\n",
    "print(f\"  - minInfoGain: {bestModel_dt.getMinInfoGain()}\")\n",
    "print(f\"RMSE: {dt_rmse:.4f}\")\n",
    "print(f\"R²: {dt_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be95d9cd",
   "metadata": {},
   "source": [
    "#### 4.3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aeea76fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/27 07:59:29 WARN DAGScheduler: Broadcasting large task binary with size 1065.9 KiB\n",
      "25/10/27 07:59:29 WARN DAGScheduler: Broadcasting large task binary with size 1556.2 KiB\n",
      "25/10/27 07:59:33 WARN DAGScheduler: Broadcasting large task binary with size 1065.9 KiB\n",
      "25/10/27 07:59:33 WARN DAGScheduler: Broadcasting large task binary with size 1556.2 KiB\n",
      "25/10/27 07:59:34 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/10/27 07:59:34 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "25/10/27 07:59:35 WARN DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n",
      "25/10/27 07:59:36 WARN DAGScheduler: Broadcasting large task binary with size 6.3 MiB\n",
      "25/10/27 07:59:38 WARN DAGScheduler: Broadcasting large task binary with size 8.3 MiB\n",
      "25/10/27 07:59:42 WARN DAGScheduler: Broadcasting large task binary with size 1065.9 KiB\n",
      "25/10/27 07:59:42 WARN DAGScheduler: Broadcasting large task binary with size 1556.2 KiB\n",
      "25/10/27 07:59:43 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/10/27 07:59:43 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "25/10/27 07:59:44 WARN DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n",
      "25/10/27 07:59:45 WARN DAGScheduler: Broadcasting large task binary with size 6.3 MiB\n",
      "25/10/27 07:59:47 WARN DAGScheduler: Broadcasting large task binary with size 8.3 MiB\n",
      "25/10/27 07:59:48 WARN DAGScheduler: Broadcasting large task binary with size 10.8 MiB\n",
      "25/10/27 07:59:50 WARN DAGScheduler: Broadcasting large task binary with size 13.6 MiB\n",
      "25/10/27 07:59:51 WARN DAGScheduler: Broadcasting large task binary with size 1009.2 KiB\n",
      "25/10/27 07:59:53 WARN DAGScheduler: Broadcasting large task binary with size 16.8 MiB\n",
      "25/10/27 07:59:54 WARN DAGScheduler: Broadcasting large task binary with size 1164.7 KiB\n",
      "25/10/27 07:59:55 WARN DAGScheduler: Broadcasting large task binary with size 20.3 MiB\n",
      "25/10/27 07:59:56 WARN DAGScheduler: Broadcasting large task binary with size 1316.7 KiB\n",
      "25/10/27 07:59:58 WARN DAGScheduler: Broadcasting large task binary with size 23.9 MiB\n",
      "25/10/27 07:59:59 WARN DAGScheduler: Broadcasting large task binary with size 1441.2 KiB\n",
      "25/10/27 08:00:04 WARN DAGScheduler: Broadcasting large task binary with size 1079.6 KiB\n",
      "25/10/27 08:00:04 WARN DAGScheduler: Broadcasting large task binary with size 1672.0 KiB\n",
      "25/10/27 08:00:05 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "25/10/27 08:00:09 WARN DAGScheduler: Broadcasting large task binary with size 1079.6 KiB\n",
      "25/10/27 08:00:10 WARN DAGScheduler: Broadcasting large task binary with size 1672.0 KiB\n",
      "25/10/27 08:00:11 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "25/10/27 08:00:13 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "25/10/27 08:00:15 WARN DAGScheduler: Broadcasting large task binary with size 6.1 MiB\n",
      "25/10/27 08:00:17 WARN DAGScheduler: Broadcasting large task binary with size 8.7 MiB\n",
      "25/10/27 08:00:20 WARN DAGScheduler: Broadcasting large task binary with size 12.1 MiB\n",
      "25/10/27 08:00:22 WARN DAGScheduler: Broadcasting large task binary with size 1071.5 KiB\n",
      "25/10/27 08:00:23 WARN DAGScheduler: Broadcasting large task binary with size 16.2 MiB\n",
      "25/10/27 08:00:25 WARN DAGScheduler: Broadcasting large task binary with size 1354.0 KiB\n",
      "25/10/27 08:00:29 WARN DAGScheduler: Broadcasting large task binary with size 1079.6 KiB\n",
      "25/10/27 08:00:30 WARN DAGScheduler: Broadcasting large task binary with size 1672.0 KiB\n",
      "25/10/27 08:00:31 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "25/10/27 08:00:32 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "25/10/27 08:00:34 WARN DAGScheduler: Broadcasting large task binary with size 6.1 MiB\n",
      "25/10/27 08:00:37 WARN DAGScheduler: Broadcasting large task binary with size 8.7 MiB\n",
      "25/10/27 08:00:39 WARN DAGScheduler: Broadcasting large task binary with size 12.1 MiB\n",
      "25/10/27 08:00:41 WARN DAGScheduler: Broadcasting large task binary with size 1071.5 KiB\n",
      "25/10/27 08:00:42 WARN DAGScheduler: Broadcasting large task binary with size 16.2 MiB\n",
      "25/10/27 08:00:44 WARN DAGScheduler: Broadcasting large task binary with size 1354.0 KiB\n",
      "25/10/27 08:00:46 WARN DAGScheduler: Broadcasting large task binary with size 21.2 MiB\n",
      "25/10/27 08:00:48 WARN DAGScheduler: Broadcasting large task binary with size 1684.8 KiB\n",
      "25/10/27 08:00:50 WARN DAGScheduler: Broadcasting large task binary with size 26.9 MiB\n",
      "25/10/27 08:00:52 WARN DAGScheduler: Broadcasting large task binary with size 2028.1 KiB\n",
      "25/10/27 08:00:54 WARN DAGScheduler: Broadcasting large task binary with size 33.3 MiB\n",
      "25/10/27 08:00:57 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "25/10/27 08:01:00 WARN DAGScheduler: Broadcasting large task binary with size 40.3 MiB\n",
      "25/10/27 08:01:03 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "25/10/27 08:01:06 WARN DAGScheduler: Broadcasting large task binary with size 47.7 MiB\n",
      "25/10/27 08:01:09 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "25/10/27 08:01:16 WARN DAGScheduler: Broadcasting large task binary with size 1392.4 KiB\n",
      "25/10/27 08:01:17 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/10/27 08:01:19 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "25/10/27 08:01:25 WARN DAGScheduler: Broadcasting large task binary with size 1392.4 KiB\n",
      "25/10/27 08:01:26 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/10/27 08:01:28 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "25/10/27 08:01:30 WARN DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "25/10/27 08:01:33 WARN DAGScheduler: Broadcasting large task binary with size 8.9 MiB\n",
      "25/10/27 08:01:37 WARN DAGScheduler: Broadcasting large task binary with size 13.0 MiB\n",
      "25/10/27 08:01:40 WARN DAGScheduler: Broadcasting large task binary with size 1231.5 KiB\n",
      "25/10/27 08:01:41 WARN DAGScheduler: Broadcasting large task binary with size 18.2 MiB\n",
      "25/10/27 08:01:44 WARN DAGScheduler: Broadcasting large task binary with size 1630.6 KiB\n",
      "25/10/27 08:01:46 WARN DAGScheduler: Broadcasting large task binary with size 24.5 MiB\n",
      "25/10/27 08:01:50 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/10/27 08:01:56 WARN DAGScheduler: Broadcasting large task binary with size 1392.4 KiB\n",
      "25/10/27 08:01:57 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/10/27 08:01:59 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "25/10/27 08:02:02 WARN DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n",
      "25/10/27 08:02:04 WARN DAGScheduler: Broadcasting large task binary with size 8.9 MiB\n",
      "25/10/27 08:02:08 WARN DAGScheduler: Broadcasting large task binary with size 13.0 MiB\n",
      "25/10/27 08:02:11 WARN DAGScheduler: Broadcasting large task binary with size 1231.5 KiB\n",
      "25/10/27 08:02:13 WARN DAGScheduler: Broadcasting large task binary with size 18.2 MiB\n",
      "25/10/27 08:02:16 WARN DAGScheduler: Broadcasting large task binary with size 1630.6 KiB\n",
      "25/10/27 08:02:18 WARN DAGScheduler: Broadcasting large task binary with size 24.5 MiB\n",
      "25/10/27 08:02:21 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/10/27 08:02:24 WARN DAGScheduler: Broadcasting large task binary with size 32.0 MiB\n",
      "25/10/27 08:02:28 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "25/10/27 08:02:31 WARN DAGScheduler: Broadcasting large task binary with size 40.7 MiB\n",
      "25/10/27 08:02:35 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "25/10/27 08:02:40 WARN DAGScheduler: Broadcasting large task binary with size 49.6 MiB\n",
      "25/10/27 08:02:46 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "25/10/27 08:02:50 WARN DAGScheduler: Broadcasting large task binary with size 53.2 MiB\n",
      "25/10/27 08:02:56 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "25/10/27 08:03:01 WARN DAGScheduler: Broadcasting large task binary with size 57.5 MiB\n",
      "25/10/27 08:03:06 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "25/10/27 08:03:09 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "25/10/27 08:03:11 WARN DAGScheduler: Broadcasting large task binary with size 9.7 MiB\n",
      "25/10/27 08:03:12 WARN DAGScheduler: Broadcasting large task binary with size 1835.8 KiB\n",
      "25/10/27 08:03:40 WARN DAGScheduler: Broadcasting large task binary with size 1049.7 KiB\n",
      "25/10/27 08:03:41 WARN DAGScheduler: Broadcasting large task binary with size 1532.7 KiB\n",
      "25/10/27 08:03:44 WARN DAGScheduler: Broadcasting large task binary with size 1049.7 KiB\n",
      "25/10/27 08:03:45 WARN DAGScheduler: Broadcasting large task binary with size 1532.7 KiB\n",
      "25/10/27 08:03:45 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/10/27 08:03:46 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "25/10/27 08:03:47 WARN DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n",
      "25/10/27 08:03:48 WARN DAGScheduler: Broadcasting large task binary with size 6.4 MiB\n",
      "25/10/27 08:03:50 WARN DAGScheduler: Broadcasting large task binary with size 8.6 MiB\n",
      "25/10/27 08:03:54 WARN DAGScheduler: Broadcasting large task binary with size 1049.7 KiB\n",
      "25/10/27 08:03:55 WARN DAGScheduler: Broadcasting large task binary with size 1532.7 KiB\n",
      "25/10/27 08:03:55 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/10/27 08:03:56 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "25/10/27 08:03:57 WARN DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n",
      "25/10/27 08:03:58 WARN DAGScheduler: Broadcasting large task binary with size 6.4 MiB\n",
      "25/10/27 08:04:00 WARN DAGScheduler: Broadcasting large task binary with size 8.6 MiB\n",
      "25/10/27 08:04:02 WARN DAGScheduler: Broadcasting large task binary with size 11.3 MiB\n",
      "25/10/27 08:04:04 WARN DAGScheduler: Broadcasting large task binary with size 14.3 MiB\n",
      "25/10/27 08:04:05 WARN DAGScheduler: Broadcasting large task binary with size 1074.7 KiB\n",
      "25/10/27 08:04:07 WARN DAGScheduler: Broadcasting large task binary with size 17.6 MiB\n",
      "25/10/27 08:04:08 WARN DAGScheduler: Broadcasting large task binary with size 1236.1 KiB\n",
      "25/10/27 08:04:10 WARN DAGScheduler: Broadcasting large task binary with size 21.3 MiB\n",
      "25/10/27 08:04:11 WARN DAGScheduler: Broadcasting large task binary with size 1391.5 KiB\n",
      "25/10/27 08:04:13 WARN DAGScheduler: Broadcasting large task binary with size 25.1 MiB\n",
      "25/10/27 08:04:14 WARN DAGScheduler: Broadcasting large task binary with size 1521.4 KiB\n",
      "25/10/27 08:04:19 WARN DAGScheduler: Broadcasting large task binary with size 1079.5 KiB\n",
      "25/10/27 08:04:20 WARN DAGScheduler: Broadcasting large task binary with size 1668.2 KiB\n",
      "25/10/27 08:04:21 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "25/10/27 08:04:25 WARN DAGScheduler: Broadcasting large task binary with size 1079.5 KiB\n",
      "25/10/27 08:04:26 WARN DAGScheduler: Broadcasting large task binary with size 1668.2 KiB\n",
      "25/10/27 08:04:27 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "25/10/27 08:04:29 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/10/27 08:04:31 WARN DAGScheduler: Broadcasting large task binary with size 6.1 MiB\n",
      "25/10/27 08:04:33 WARN DAGScheduler: Broadcasting large task binary with size 8.9 MiB\n",
      "25/10/27 08:04:36 WARN DAGScheduler: Broadcasting large task binary with size 12.5 MiB\n",
      "25/10/27 08:04:38 WARN DAGScheduler: Broadcasting large task binary with size 1119.0 KiB\n",
      "25/10/27 08:04:40 WARN DAGScheduler: Broadcasting large task binary with size 16.7 MiB\n",
      "25/10/27 08:04:42 WARN DAGScheduler: Broadcasting large task binary with size 1415.6 KiB\n",
      "25/10/27 08:04:46 WARN DAGScheduler: Broadcasting large task binary with size 1079.5 KiB\n",
      "25/10/27 08:04:47 WARN DAGScheduler: Broadcasting large task binary with size 1668.2 KiB\n",
      "25/10/27 08:04:48 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "25/10/27 08:04:50 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "25/10/27 08:04:52 WARN DAGScheduler: Broadcasting large task binary with size 6.1 MiB\n",
      "25/10/27 08:04:54 WARN DAGScheduler: Broadcasting large task binary with size 8.9 MiB\n",
      "25/10/27 08:04:57 WARN DAGScheduler: Broadcasting large task binary with size 12.5 MiB\n",
      "25/10/27 08:05:00 WARN DAGScheduler: Broadcasting large task binary with size 1119.0 KiB\n",
      "25/10/27 08:05:01 WARN DAGScheduler: Broadcasting large task binary with size 16.7 MiB\n",
      "25/10/27 08:05:03 WARN DAGScheduler: Broadcasting large task binary with size 1415.6 KiB\n",
      "25/10/27 08:05:05 WARN DAGScheduler: Broadcasting large task binary with size 21.9 MiB\n",
      "25/10/27 08:05:07 WARN DAGScheduler: Broadcasting large task binary with size 1744.2 KiB\n",
      "25/10/27 08:05:10 WARN DAGScheduler: Broadcasting large task binary with size 27.6 MiB\n",
      "25/10/27 08:05:12 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "25/10/27 08:05:15 WARN DAGScheduler: Broadcasting large task binary with size 34.0 MiB\n",
      "25/10/27 08:05:18 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "25/10/27 08:05:21 WARN DAGScheduler: Broadcasting large task binary with size 41.1 MiB\n",
      "25/10/27 08:05:24 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "25/10/27 08:05:28 WARN DAGScheduler: Broadcasting large task binary with size 48.6 MiB\n",
      "25/10/27 08:05:32 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "25/10/27 08:05:40 WARN DAGScheduler: Broadcasting large task binary with size 1391.2 KiB\n",
      "25/10/27 08:05:41 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/10/27 08:05:43 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "25/10/27 08:05:49 WARN DAGScheduler: Broadcasting large task binary with size 1391.2 KiB\n",
      "25/10/27 08:05:50 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/10/27 08:05:52 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "25/10/27 08:05:54 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n",
      "25/10/27 08:05:57 WARN DAGScheduler: Broadcasting large task binary with size 8.9 MiB\n",
      "25/10/27 08:06:00 WARN DAGScheduler: Broadcasting large task binary with size 13.3 MiB\n",
      "25/10/27 08:06:03 WARN DAGScheduler: Broadcasting large task binary with size 1269.0 KiB\n",
      "25/10/27 08:06:04 WARN DAGScheduler: Broadcasting large task binary with size 18.6 MiB\n",
      "25/10/27 08:06:07 WARN DAGScheduler: Broadcasting large task binary with size 1695.0 KiB\n",
      "25/10/27 08:06:09 WARN DAGScheduler: Broadcasting large task binary with size 25.3 MiB\n",
      "25/10/27 08:06:12 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/10/27 08:06:17 WARN DAGScheduler: Broadcasting large task binary with size 1391.2 KiB\n",
      "25/10/27 08:06:18 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/10/27 08:06:20 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "25/10/27 08:06:22 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n",
      "25/10/27 08:06:25 WARN DAGScheduler: Broadcasting large task binary with size 8.9 MiB\n",
      "25/10/27 08:06:29 WARN DAGScheduler: Broadcasting large task binary with size 13.3 MiB\n",
      "25/10/27 08:06:32 WARN DAGScheduler: Broadcasting large task binary with size 1269.0 KiB\n",
      "25/10/27 08:06:33 WARN DAGScheduler: Broadcasting large task binary with size 18.6 MiB\n",
      "25/10/27 08:06:37 WARN DAGScheduler: Broadcasting large task binary with size 1695.0 KiB\n",
      "25/10/27 08:06:38 WARN DAGScheduler: Broadcasting large task binary with size 25.3 MiB\n",
      "25/10/27 08:06:42 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/10/27 08:06:44 WARN DAGScheduler: Broadcasting large task binary with size 33.1 MiB\n",
      "25/10/27 08:06:48 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "25/10/27 08:06:51 WARN DAGScheduler: Broadcasting large task binary with size 41.9 MiB\n",
      "25/10/27 08:06:55 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "25/10/27 08:06:59 WARN DAGScheduler: Broadcasting large task binary with size 49.8 MiB\n",
      "25/10/27 08:07:04 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "25/10/27 08:07:09 WARN DAGScheduler: Broadcasting large task binary with size 53.5 MiB\n",
      "25/10/27 08:07:13 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "25/10/27 08:07:18 WARN DAGScheduler: Broadcasting large task binary with size 57.8 MiB\n",
      "25/10/27 08:07:23 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "25/10/27 08:07:27 WARN DAGScheduler: Broadcasting large task binary with size 15.0 MiB\n",
      "25/10/27 08:07:28 WARN DAGScheduler: Broadcasting large task binary with size 11.1 MiB\n",
      "25/10/27 08:07:29 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "25/10/27 08:07:58 WARN DAGScheduler: Broadcasting large task binary with size 1047.4 KiB\n",
      "25/10/27 08:07:59 WARN DAGScheduler: Broadcasting large task binary with size 1535.0 KiB\n",
      "25/10/27 08:08:02 WARN DAGScheduler: Broadcasting large task binary with size 1047.4 KiB\n",
      "25/10/27 08:08:03 WARN DAGScheduler: Broadcasting large task binary with size 1535.0 KiB\n",
      "25/10/27 08:08:03 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/10/27 08:08:04 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "25/10/27 08:08:05 WARN DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n",
      "25/10/27 08:08:06 WARN DAGScheduler: Broadcasting large task binary with size 6.4 MiB\n",
      "25/10/27 08:08:07 WARN DAGScheduler: Broadcasting large task binary with size 8.5 MiB\n",
      "25/10/27 08:08:11 WARN DAGScheduler: Broadcasting large task binary with size 1047.4 KiB\n",
      "25/10/27 08:08:11 WARN DAGScheduler: Broadcasting large task binary with size 1535.0 KiB\n",
      "25/10/27 08:08:12 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/10/27 08:08:13 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "25/10/27 08:08:13 WARN DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n",
      "25/10/27 08:08:14 WARN DAGScheduler: Broadcasting large task binary with size 6.4 MiB\n",
      "25/10/27 08:08:16 WARN DAGScheduler: Broadcasting large task binary with size 8.5 MiB\n",
      "25/10/27 08:08:18 WARN DAGScheduler: Broadcasting large task binary with size 11.1 MiB\n",
      "25/10/27 08:08:20 WARN DAGScheduler: Broadcasting large task binary with size 14.0 MiB\n",
      "25/10/27 08:08:21 WARN DAGScheduler: Broadcasting large task binary with size 1041.4 KiB\n",
      "25/10/27 08:08:22 WARN DAGScheduler: Broadcasting large task binary with size 17.2 MiB\n",
      "25/10/27 08:08:23 WARN DAGScheduler: Broadcasting large task binary with size 1198.9 KiB\n",
      "25/10/27 08:08:25 WARN DAGScheduler: Broadcasting large task binary with size 20.8 MiB\n",
      "25/10/27 08:08:27 WARN DAGScheduler: Broadcasting large task binary with size 1354.8 KiB\n",
      "25/10/27 08:08:29 WARN DAGScheduler: Broadcasting large task binary with size 24.7 MiB\n",
      "25/10/27 08:08:30 WARN DAGScheduler: Broadcasting large task binary with size 1496.4 KiB\n",
      "25/10/27 08:08:34 WARN DAGScheduler: Broadcasting large task binary with size 1078.0 KiB\n",
      "25/10/27 08:08:35 WARN DAGScheduler: Broadcasting large task binary with size 1668.1 KiB\n",
      "25/10/27 08:08:36 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "25/10/27 08:08:40 WARN DAGScheduler: Broadcasting large task binary with size 1078.0 KiB\n",
      "25/10/27 08:08:41 WARN DAGScheduler: Broadcasting large task binary with size 1668.1 KiB\n",
      "25/10/27 08:08:42 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "25/10/27 08:08:43 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "25/10/27 08:08:45 WARN DAGScheduler: Broadcasting large task binary with size 6.1 MiB\n",
      "25/10/27 08:08:47 WARN DAGScheduler: Broadcasting large task binary with size 8.9 MiB\n",
      "25/10/27 08:08:50 WARN DAGScheduler: Broadcasting large task binary with size 12.3 MiB\n",
      "25/10/27 08:08:52 WARN DAGScheduler: Broadcasting large task binary with size 1098.9 KiB\n",
      "25/10/27 08:08:53 WARN DAGScheduler: Broadcasting large task binary with size 16.5 MiB\n",
      "25/10/27 08:08:56 WARN DAGScheduler: Broadcasting large task binary with size 1393.3 KiB\n",
      "25/10/27 08:09:00 WARN DAGScheduler: Broadcasting large task binary with size 1078.0 KiB\n",
      "25/10/27 08:09:00 WARN DAGScheduler: Broadcasting large task binary with size 1668.1 KiB\n",
      "25/10/27 08:09:01 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "25/10/27 08:09:03 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "25/10/27 08:09:05 WARN DAGScheduler: Broadcasting large task binary with size 6.1 MiB\n",
      "25/10/27 08:09:07 WARN DAGScheduler: Broadcasting large task binary with size 8.9 MiB\n",
      "25/10/27 08:09:09 WARN DAGScheduler: Broadcasting large task binary with size 12.3 MiB\n",
      "25/10/27 08:09:11 WARN DAGScheduler: Broadcasting large task binary with size 1098.9 KiB\n",
      "25/10/27 08:09:13 WARN DAGScheduler: Broadcasting large task binary with size 16.5 MiB\n",
      "25/10/27 08:09:15 WARN DAGScheduler: Broadcasting large task binary with size 1393.3 KiB\n",
      "25/10/27 08:09:16 WARN DAGScheduler: Broadcasting large task binary with size 21.5 MiB\n",
      "25/10/27 08:09:19 WARN DAGScheduler: Broadcasting large task binary with size 1703.4 KiB\n",
      "25/10/27 08:09:21 WARN DAGScheduler: Broadcasting large task binary with size 27.3 MiB\n",
      "25/10/27 08:09:24 WARN DAGScheduler: Broadcasting large task binary with size 2041.7 KiB\n",
      "25/10/27 08:09:26 WARN DAGScheduler: Broadcasting large task binary with size 33.8 MiB\n",
      "25/10/27 08:09:29 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "25/10/27 08:09:32 WARN DAGScheduler: Broadcasting large task binary with size 40.9 MiB\n",
      "25/10/27 08:09:35 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "25/10/27 08:09:39 WARN DAGScheduler: Broadcasting large task binary with size 48.4 MiB\n",
      "25/10/27 08:09:42 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "25/10/27 08:09:50 WARN DAGScheduler: Broadcasting large task binary with size 1385.6 KiB\n",
      "25/10/27 08:09:51 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/10/27 08:09:53 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n",
      "25/10/27 08:09:59 WARN DAGScheduler: Broadcasting large task binary with size 1385.6 KiB\n",
      "25/10/27 08:10:01 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/10/27 08:10:03 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n",
      "25/10/27 08:10:05 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n",
      "25/10/27 08:10:08 WARN DAGScheduler: Broadcasting large task binary with size 8.9 MiB\n",
      "25/10/27 08:10:12 WARN DAGScheduler: Broadcasting large task binary with size 13.1 MiB\n",
      "25/10/27 08:10:15 WARN DAGScheduler: Broadcasting large task binary with size 1242.2 KiB\n",
      "25/10/27 08:10:16 WARN DAGScheduler: Broadcasting large task binary with size 18.3 MiB\n",
      "25/10/27 08:10:19 WARN DAGScheduler: Broadcasting large task binary with size 1649.2 KiB\n",
      "25/10/27 08:10:21 WARN DAGScheduler: Broadcasting large task binary with size 24.6 MiB\n",
      "25/10/27 08:10:25 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/10/27 08:10:30 WARN DAGScheduler: Broadcasting large task binary with size 1385.6 KiB\n",
      "25/10/27 08:10:31 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/10/27 08:10:33 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n",
      "25/10/27 08:10:36 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n",
      "25/10/27 08:10:40 WARN DAGScheduler: Broadcasting large task binary with size 8.9 MiB\n",
      "25/10/27 08:10:43 WARN DAGScheduler: Broadcasting large task binary with size 13.1 MiB\n",
      "25/10/27 08:10:46 WARN DAGScheduler: Broadcasting large task binary with size 1242.2 KiB\n",
      "25/10/27 08:10:47 WARN DAGScheduler: Broadcasting large task binary with size 18.3 MiB\n",
      "25/10/27 08:10:50 WARN DAGScheduler: Broadcasting large task binary with size 1649.2 KiB\n",
      "25/10/27 08:10:52 WARN DAGScheduler: Broadcasting large task binary with size 24.6 MiB\n",
      "25/10/27 08:10:56 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/10/27 08:10:59 WARN DAGScheduler: Broadcasting large task binary with size 32.2 MiB\n",
      "25/10/27 08:11:03 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "25/10/27 08:11:07 WARN DAGScheduler: Broadcasting large task binary with size 41.0 MiB\n",
      "25/10/27 08:11:11 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "25/10/27 08:11:16 WARN DAGScheduler: Broadcasting large task binary with size 49.8 MiB\n",
      "25/10/27 08:11:21 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "25/10/27 08:11:26 WARN DAGScheduler: Broadcasting large task binary with size 53.7 MiB\n",
      "25/10/27 08:11:30 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "25/10/27 08:11:36 WARN DAGScheduler: Broadcasting large task binary with size 57.8 MiB\n",
      "25/10/27 08:11:41 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "25/10/27 08:11:44 WARN DAGScheduler: Broadcasting large task binary with size 13.5 MiB\n",
      "25/10/27 08:11:46 WARN DAGScheduler: Broadcasting large task binary with size 9.0 MiB\n",
      "25/10/27 08:11:47 WARN DAGScheduler: Broadcasting large task binary with size 1869.9 KiB\n",
      "25/10/27 08:11:55 WARN DAGScheduler: Broadcasting large task binary with size 1381.8 KiB\n",
      "25/10/27 08:11:57 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "25/10/27 08:12:00 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "25/10/27 08:12:04 WARN DAGScheduler: Broadcasting large task binary with size 6.2 MiB\n",
      "25/10/27 08:12:08 WARN DAGScheduler: Broadcasting large task binary with size 9.8 MiB\n",
      "25/10/27 08:12:12 WARN DAGScheduler: Broadcasting large task binary with size 1000.9 KiB\n",
      "25/10/27 08:12:13 WARN DAGScheduler: Broadcasting large task binary with size 14.6 MiB\n",
      "25/10/27 08:12:17 WARN DAGScheduler: Broadcasting large task binary with size 1422.8 KiB\n",
      "25/10/27 08:12:19 WARN DAGScheduler: Broadcasting large task binary with size 20.6 MiB\n",
      "25/10/27 08:12:24 WARN DAGScheduler: Broadcasting large task binary with size 1911.9 KiB\n",
      "25/10/27 08:12:26 WARN DAGScheduler: Broadcasting large task binary with size 28.2 MiB\n",
      "25/10/27 08:12:31 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "25/10/27 08:12:34 WARN DAGScheduler: Broadcasting large task binary with size 37.3 MiB\n",
      "25/10/27 08:12:39 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "25/10/27 08:12:44 WARN DAGScheduler: Broadcasting large task binary with size 43.9 MiB\n",
      "25/10/27 08:12:50 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "25/10/27 08:12:54 WARN DAGScheduler: Broadcasting large task binary with size 46.7 MiB\n",
      "25/10/27 08:12:59 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "25/10/27 08:13:04 WARN DAGScheduler: Broadcasting large task binary with size 49.9 MiB\n",
      "25/10/27 08:13:09 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "25/10/27 08:13:14 WARN DAGScheduler: Broadcasting large task binary with size 53.3 MiB\n",
      "25/10/27 08:13:19 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "25/10/27 08:13:23 WARN DAGScheduler: Broadcasting large task binary with size 26.9 MiB\n",
      "25/10/27 08:13:25 WARN DAGScheduler: Broadcasting large task binary with size 1861.3 KiB\n",
      "25/10/27 08:13:27 WARN DAGScheduler: Broadcasting large task binary with size 24.4 MiB\n",
      "25/10/27 08:13:29 WARN DAGScheduler: Broadcasting large task binary with size 1608.7 KiB\n",
      "25/10/27 08:13:31 WARN DAGScheduler: Broadcasting large task binary with size 18.7 MiB\n",
      "25/10/27 08:13:32 WARN DAGScheduler: Broadcasting large task binary with size 1173.5 KiB\n",
      "25/10/27 08:13:33 WARN DAGScheduler: Broadcasting large task binary with size 8.0 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 181194.8568 | R² = 0.7811\n",
      "Best Parameters:\n",
      "  - numTrees: 300\n",
      "  - maxDepth: <bound method _DecisionTreeParams.getMaxDepth of RandomForestRegressionModel: uid=RandomForestRegressor_89b53cc54add, numTrees=300, numFeatures=421>\n",
      "  - maxBins: <bound method _DecisionTreeParams.getMaxBins of RandomForestRegressionModel: uid=RandomForestRegressor_89b53cc54add, numTrees=300, numFeatures=421>\n",
      "  - minInstancesPerNode: <bound method _DecisionTreeParams.getMinInstancesPerNode of RandomForestRegressionModel: uid=RandomForestRegressor_89b53cc54add, numTrees=300, numFeatures=421>\n",
      "RMSE: 181194.8568\n",
      "R²: 0.7811\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining Random Forest...\")\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=label_col\n",
    ")\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.numTrees, [100, 200, 300])\n",
    "             .addGrid(rf.maxDepth, [5, 10, 15])\n",
    "             .addGrid(rf.maxBins, [32])\n",
    "             .addGrid(rf.minInstancesPerNode, [1])\n",
    "             .build())\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "crossval = CrossValidator(estimator=rf,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3,\n",
    "                          parallelism=1)\n",
    "\n",
    "cvModel = crossval.fit(train_data)\n",
    "bestModel_rf = cvModel.bestModel\n",
    "\n",
    "pred_rf = bestModel_rf.transform(valid_data)\n",
    "\n",
    "rf_rmse, rf_r2 = evaluate(pred_rf, label_col)\n",
    "\n",
    "print(f\"Best Parameters:\")\n",
    "print(f\"  - numTrees: {bestModel_rf.getNumTrees}\")\n",
    "print(f\"  - maxDepth: {bestModel_rf.getMaxDepth}\")\n",
    "print(f\"  - maxBins: {bestModel_rf.getMaxBins}\")\n",
    "print(f\"  - minInstancesPerNode: {bestModel_rf.getMinInstancesPerNode}\")\n",
    "print(f\"RMSE: {rf_rmse:.4f}\")\n",
    "print(f\"R²: {rf_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc60465",
   "metadata": {},
   "source": [
    "#### 4.4. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e46c0620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-27 08:14:07,249 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:14:07,250 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:14:11] task 0 got new rank 0[08:14:11] task 0 got new rank 0    (0 + 1) / 1]\n",
      "\n",
      "2025-10-27 08:14:13,133 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:14:13,134 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:14:15,191 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:14:15,199 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:14:16] task 0 got new rank 0 1) / 1][Stage 4507:>               (0 + 1) / 1]\n",
      "[08:14:16] task 0 got new rank 0\n",
      "2025-10-27 08:14:17,935 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:14:17,957 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:14:19,019 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:14:19,056 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:14:20] task 0 got new rank 0 1) / 1][Stage 4515:>               (0 + 1) / 1]\n",
      "[08:14:20] task 0 got new rank 0\n",
      "2025-10-27 08:14:21,727 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:14:21,782 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:14:22,951 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:14:22,982 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:14:24] task 0 got new rank 0 1) / 1][Stage 4523:>               (0 + 1) / 1]\n",
      "[08:14:24] task 0 got new rank 0\n",
      "2025-10-27 08:14:25,686 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:14:25,716 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:14:26,747 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:14:26,798 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:14:28] task 0 got new rank 0 1) / 1][Stage 4531:>               (0 + 1) / 1]\n",
      "[08:14:28] task 0 got new rank 0\n",
      "2025-10-27 08:14:29,457 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:14:29,507 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:14:30,547 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:14:30,623 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:14:31] task 0 got new rank 0 1) / 1][Stage 4539:>               (0 + 1) / 1]\n",
      "[08:14:32] task 0 got new rank 0\n",
      "2025-10-27 08:14:33,307 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:14:33,430 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:14:34,578 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:14:34,795 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:14:35] task 0 got new rank 0 1) / 1][Stage 4547:>               (0 + 1) / 1]\n",
      "[08:14:36] task 0 got new rank 0\n",
      "2025-10-27 08:14:37,313 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:14:37,611 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:14:38,422 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:14:38,839 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:14:39] task 0 got new rank 0 1) / 1][Stage 4555:>               (0 + 1) / 1]\n",
      "[08:14:40] task 0 got new rank 0\n",
      "2025-10-27 08:14:41,280 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:14:41,625 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:14:42,537 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:14:42,894 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:14:43] task 0 got new rank 0 1) / 1][Stage 4563:>               (0 + 1) / 1]\n",
      "[08:14:44] task 0 got new rank 0\n",
      "2025-10-27 08:14:45,313 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:14:45,705 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:14:46,415 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:14:46,959 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:14:47] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "[08:14:48] task 0 got new rank 0 1) / 1][Stage 4571:>               (0 + 1) / 1]\n",
      "2025-10-27 08:14:49,123 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:14:49,661 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-10-27 08:14:50,122 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:14:50,798 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:14:51] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "[08:14:52] task 0 got new rank 0 1) / 1][Stage 4579:>               (0 + 1) / 1]\n",
      "2025-10-27 08:14:52,846 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs                   (0 + 1) / 1]\n",
      "2025-10-27 08:14:53,481 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:14:53,885 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:14:54,680 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:14:55] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "[08:14:56] task 0 got new rank 0 1) / 1][Stage 4587:>               (0 + 1) / 1]\n",
      "2025-10-27 08:14:56,647 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs                   (0 + 1) / 1]\n",
      "2025-10-27 08:14:57,410 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:14:57,797 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:14:58,602 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:14:59] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "[08:14:59] task 0 got new rank 0 1) / 1][Stage 4595:>               (0 + 1) / 1]\n",
      "2025-10-27 08:15:00,884 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "25/10/27 08:15:01 WARN DAGScheduler: Broadcasting large task binary with size 1198.3 KiB\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:15:01,594 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:15:02,059 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "25/10/27 08:15:02 WARN DAGScheduler: Broadcasting large task binary with size 1191.4 KiB\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:15:02,806 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:15:03] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "[08:15:04] task 0 got new rank 0 1) / 1][Stage 4603:>               (0 + 1) / 1]\n",
      "2025-10-27 08:15:05,134 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "25/10/27 08:15:05 WARN DAGScheduler: Broadcasting large task binary with size 1288.0 KiB\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:15:05,881 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-10-27 08:15:06,268 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "25/10/27 08:15:06 WARN DAGScheduler: Broadcasting large task binary with size 1262.8 KiB\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:15:07,144 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:15:07] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "[08:15:08] task 0 got new rank 0 1) / 1][Stage 4611:>               (0 + 1) / 1]\n",
      "2025-10-27 08:15:09,201 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:15:10,024 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:15:10,337 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:15:11,398 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:15:11] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "[08:15:12] task 0 got new rank 0 1) / 1][Stage 4619:>               (0 + 1) / 1]\n",
      "2025-10-27 08:15:13,247 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs                   (0 + 1) / 1]\n",
      "2025-10-27 08:15:14,240 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:15:14,344 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "25/10/27 08:15:14 WARN DAGScheduler: Broadcasting large task binary with size 1006.2 KiB\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:15:15,496 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:15:15] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "[08:15:16] task 0 got new rank 0 1) / 1][Stage 4627:>               (0 + 1) / 1]\n",
      "2025-10-27 08:15:17,101 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs                   (0 + 1) / 1]\n",
      "2025-10-27 08:15:18,145 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:15:18,233 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:15:19,459 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:15:19] task 0 got new rank 0\n",
      "[08:15:20] task 0 got new rank 0 1) / 1][Stage 4635:>               (0 + 1) / 1]\n",
      "2025-10-27 08:15:20,980 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:15:22,278 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:15:50,138 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:15:50,140 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:15:51] task 0 got new rank 0 1) / 1][Stage 4648:>               (0 + 1) / 1]\n",
      "[08:15:51] task 0 got new rank 0\n",
      "2025-10-27 08:15:52,863 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:15:52,864 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:15:54,479 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:15:54,502 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:15:55] task 0 got new rank 0 1) / 1][Stage 4661:>               (0 + 1) / 1]\n",
      "[08:15:55] task 0 got new rank 0\n",
      "2025-10-27 08:15:57,158 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:15:57,172 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:15:58,319 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:15:58,329 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:15:59] task 0 got new rank 0 1) / 1][Stage 4669:>               (0 + 1) / 1]\n",
      "[08:15:59] task 0 got new rank 0\n",
      "2025-10-27 08:16:01,010 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:16:01,028 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:16:02,178 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:16:02,246 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:16:03] task 0 got new rank 0 1) / 1][Stage 4677:>               (0 + 1) / 1]\n",
      "[08:16:03] task 0 got new rank 0\n",
      "2025-10-27 08:16:04,843 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:16:04,925 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:16:06,248 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:16:06,358 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:16:07] task 0 got new rank 0 1) / 1][Stage 4685:>               (0 + 1) / 1]\n",
      "[08:16:07] task 0 got new rank 0\n",
      "2025-10-27 08:16:08,954 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:16:09,094 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:16:10,138 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:16:10,298 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:16:11] task 0 got new rank 0 1) / 1][Stage 4693:>               (0 + 1) / 1]\n",
      "[08:16:11] task 0 got new rank 0\n",
      "2025-10-27 08:16:12,788 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:16:13,032 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:16:13,960 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:16:14,235 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:16:15] task 0 got new rank 0 1) / 1][Stage 4701:>               (0 + 1) / 1]\n",
      "[08:16:15] task 0 got new rank 0\n",
      "2025-10-27 08:16:16,708 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:16:17,044 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:16:17,903 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:16:18,312 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:16:19] task 0 got new rank 0 1) / 1][Stage 4709:>               (0 + 1) / 1]\n",
      "[08:16:19] task 0 got new rank 0\n",
      "2025-10-27 08:16:20,714 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:16:21,148 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:16:21,866 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:16:22,370 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:16:23] task 0 got new rank 0 1) / 1][Stage 4717:>               (0 + 1) / 1]\n",
      "[08:16:23] task 0 got new rank 0\n",
      "2025-10-27 08:16:24,567 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:16:25,074 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:16:25,876 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:16:26,501 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:16:27] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "[08:16:27] task 0 got new rank 0 1) / 1][Stage 4725:>               (0 + 1) / 1]\n",
      "2025-10-27 08:16:28,719 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:16:29,216 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:16:30,026 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:16:30,627 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:16:31] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "[08:16:31] task 0 got new rank 0 1) / 1][Stage 4733:>               (0 + 1) / 1]\n",
      "2025-10-27 08:16:32,813 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:16:33,342 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:16:34,092 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:16:34,780 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:16:35] task 0 got new rank 0 1) / 1][Stage 4741:>               (0 + 1) / 1]\n",
      "[08:16:36] task 0 got new rank 0\n",
      "2025-10-27 08:16:36,859 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:16:37,425 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-10-27 08:16:37,958 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:16:38,665 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:16:39] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "[08:16:40] task 0 got new rank 0 1) / 1][Stage 4749:>               (0 + 1) / 1]\n",
      "2025-10-27 08:16:41,058 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "25/10/27 08:16:41 WARN DAGScheduler: Broadcasting large task binary with size 1214.9 KiB\n",
      "2025-10-27 08:16:41,639 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:16:42,353 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "25/10/27 08:16:42 WARN DAGScheduler: Broadcasting large task binary with size 1211.9 KiB\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:16:43,027 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:16:43] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "[08:16:44] task 0 got new rank 0 1) / 1][Stage 4757:>               (0 + 1) / 1]\n",
      "2025-10-27 08:16:45,366 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "25/10/27 08:16:45 WARN DAGScheduler: Broadcasting large task binary with size 1253.6 KiB\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:16:46,093 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:16:46,538 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "25/10/27 08:16:46 WARN DAGScheduler: Broadcasting large task binary with size 1301.8 KiB\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:16:47,294 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:16:47] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "[08:16:48] task 0 got new rank 0 1) / 1][Stage 4765:>               (0 + 1) / 1]\n",
      "2025-10-27 08:16:49,407 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:16:50,139 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-10-27 08:16:50,602 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:16:51,493 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:16:52] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "[08:16:52] task 0 got new rank 0 1) / 1][Stage 4773:>               (0 + 1) / 1]\n",
      "2025-10-27 08:16:53,537 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "25/10/27 08:16:54 WARN DAGScheduler: Broadcasting large task binary with size 1014.4 KiB\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs                   (0 + 1) / 1]\n",
      "2025-10-27 08:16:54,406 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:16:54,673 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "25/10/27 08:16:55 WARN DAGScheduler: Broadcasting large task binary with size 1030.0 KiB\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:16:55,781 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:16:56] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "[08:16:57] task 0 got new rank 0 1) / 1][Stage 4781:>               (0 + 1) / 1]\n",
      "2025-10-27 08:16:57,526 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs                   (0 + 1) / 1]\n",
      "2025-10-27 08:16:58,717 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:16:58,747 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs                   (0 + 1) / 1]\n",
      "2025-10-27 08:16:59,961 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:17:00] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "[08:17:01] task 0 got new rank 0 1) / 1][Stage 4789:>               (0 + 1) / 1]\n",
      "2025-10-27 08:17:01,570 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs                   (0 + 1) / 1]\n",
      "2025-10-27 08:17:02,837 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:17:29,995 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:17:30,043 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:17:31] task 0 got new rank 0 1) / 1][Stage 4802:>               (0 + 1) / 1]\n",
      "[08:17:31] task 0 got new rank 0\n",
      "2025-10-27 08:17:32,755 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:17:32,779 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:17:34,731 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:17:34,742 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:17:36] task 0 got new rank 0 1) / 1][Stage 4815:>               (0 + 1) / 1]\n",
      "[08:17:36] task 0 got new rank 0\n",
      "2025-10-27 08:17:37,498 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:17:37,581 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:17:38,849 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:17:38,974 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:17:40] task 0 got new rank 0 1) / 1][Stage 4823:>               (0 + 1) / 1]\n",
      "[08:17:40] task 0 got new rank 0\n",
      "2025-10-27 08:17:41,610 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:17:41,802 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:17:42,888 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:17:43,217 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:17:44] task 0 got new rank 0 1) / 1][Stage 4831:>               (0 + 1) / 1]\n",
      "[08:17:44] task 0 got new rank 0\n",
      "2025-10-27 08:17:45,647 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:17:45,957 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:17:47,215 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:17:47,626 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:17:48] task 0 got new rank 0 1) / 1][Stage 4839:>               (0 + 1) / 1]\n",
      "[08:17:48] task 0 got new rank 0\n",
      "2025-10-27 08:17:49,975 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:17:50,304 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:17:51,192 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:17:51,651 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 4, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:17:52] task 0 got new rank 0 1) / 1][Stage 4847:>               (0 + 1) / 1]\n",
      "[08:17:53] task 0 got new rank 0\n",
      "2025-10-27 08:17:53,910 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:17:54,348 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:17:55,144 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:17:55,694 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:17:56] task 0 got new rank 0 1) / 1][Stage 4855:>               (0 + 1) / 1]\n",
      "[08:17:57] task 0 got new rank 0\n",
      "2025-10-27 08:17:57,946 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:17:58,485 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:17:59,168 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:17:59,856 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:18:00] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "[08:18:01] task 0 got new rank 0 1) / 1][Stage 4863:>               (0 + 1) / 1]\n",
      "2025-10-27 08:18:02,031 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:18:02,692 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2025-10-27 08:18:03,166 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:18:03,913 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:18:04] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "[08:18:05] task 0 got new rank 0 1) / 1][Stage 4871:>               (0 + 1) / 1]\n",
      "2025-10-27 08:18:05,925 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs                   (0 + 1) / 1]\n",
      "2025-10-27 08:18:06,729 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:18:07,001 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:18:07,938 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:18:08] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "[08:18:09] task 0 got new rank 0 1) / 1][Stage 4879:>               (0 + 1) / 1]\n",
      "2025-10-27 08:18:09,773 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs                   (0 + 1) / 1]\n",
      "2025-10-27 08:18:10,618 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:18:10,918 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:18:11,807 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:18:12] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "[08:18:13] task 0 got new rank 0 1) / 1][Stage 4887:>               (0 + 1) / 1]\n",
      "2025-10-27 08:18:13,608 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs                   (0 + 1) / 1]\n",
      "2025-10-27 08:18:14,551 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:18:14,678 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:18:15,780 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 6, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:18:15] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "[08:18:17] task 0 got new rank 0 1) / 1][Stage 4895:>               (0 + 1) / 1]\n",
      "2025-10-27 08:18:17,359 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs                   (0 + 1) / 1]\n",
      "2025-10-27 08:18:18,482 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "2025-10-27 08:18:18,509 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:18:19,623 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:18:19] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "[08:18:20] task 0 got new rank 0 1) / 1][Stage 4903:>               (0 + 1) / 1]\n",
      "2025-10-27 08:18:21,424 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "25/10/27 08:18:22 WARN DAGScheduler: Broadcasting large task binary with size 1175.7 KiB\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:18:22,532 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:18:22,570 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "25/10/27 08:18:23 WARN DAGScheduler: Broadcasting large task binary with size 1168.7 KiB\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:18:23,751 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.05, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:18:23] task 0 got new rank 0\n",
      "[08:18:25] task 0 got new rank 0 1) / 1][Stage 4911:>               (0 + 1) / 1]\n",
      "2025-10-27 08:18:25,597 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "25/10/27 08:18:26 WARN DAGScheduler: Broadcasting large task binary with size 1246.8 KiB\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:18:26,735 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:18:26,831 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "25/10/27 08:18:27 WARN DAGScheduler: Broadcasting large task binary with size 1259.0 KiB\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs                   (0 + 1) / 1]\n",
      "[08:18:28] task 0 got new rank 0                                                \n",
      "2025-10-27 08:18:28,100 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:18:29] task 0 got new rank 0 1) / 1][Stage 4919:>               (0 + 1) / 1]\n",
      "2025-10-27 08:18:29,624 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs                   (0 + 1) / 1]\n",
      "2025-10-27 08:18:30,741 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:18:31,027 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "[08:18:32] task 0 got new rank 0\n",
      "2025-10-27 08:18:32,087 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:18:33] task 0 got new rank 0 1) / 1][Stage 4927:>               (0 + 1) / 1]\n",
      "2025-10-27 08:18:33,549 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs                   (0 + 1) / 1]\n",
      "2025-10-27 08:18:34,660 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:18:34,937 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs                   (0 + 1) / 1]\n",
      "[08:18:35] task 0 got new rank 0                                                \n",
      "2025-10-27 08:18:36,073 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:18:37] task 0 got new rank 0 1) / 1][Stage 4935:>               (0 + 1) / 1]\n",
      "2025-10-27 08:18:37,500 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs                   (0 + 1) / 1]\n",
      "2025-10-27 08:18:38,676 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-10-27 08:18:38,954 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs                   (0 + 1) / 1]\n",
      "[08:18:39] task 0 got new rank 0                                                \n",
      "2025-10-27 08:18:40,090 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 1.0, 'device': 'cpu', 'learning_rate': 0.2, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 1.0, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:18:41] task 0 got new rank 0 1) / 1][Stage 4943:>               (0 + 1) / 1]\n",
      "2025-10-27 08:18:41,454 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:18:42,852 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "2025-10-27 08:18:44,953 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 8, 'objective': 'reg:squarederror', 'subsample': 0.8, 'eval_metric': 'rmse', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "[08:18:47] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "2025-10-27 08:18:49,323 INFO XGBoost-PySpark: _fit Finished xgboost training!   \n",
      "25/10/27 08:18:50 WARN DAGScheduler: Broadcasting large task binary with size 1023.1 KiB\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "25/10/27 08:18:52 WARN DAGScheduler: Broadcasting large task binary with size 1023.1 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 100819.6583 | R² = 0.9322\n",
      "\n",
      "Best Parameters:\n",
      "  - max_depth: 8\n",
      "  - learning_rate: 0.1\n",
      "  - subsample: 0.8\n",
      "  - colsample_bytree: 0.8\n",
      "\n",
      "Performance:\n",
      "  RMSE: 100819.6583\n",
      "  R²: 0.9322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining XGBoost...\")\n",
    "\n",
    "xgb = SparkXGBRegressor(\n",
    "    features_col=\"features\",\n",
    "    label_col=label_col,\n",
    "    objective=\"reg:squarederror\",\n",
    "    eval_metric=\"rmse\",\n",
    "    num_workers=1\n",
    ")\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(xgb.max_depth, [4, 6, 8])\n",
    "             .addGrid(xgb.learning_rate, [0.05, 0.1, 0.2])\n",
    "             .addGrid(xgb.subsample, [0.8, 1.0])\n",
    "             .addGrid(xgb.colsample_bytree, [0.8, 1.0])\n",
    "             .build())\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "crossval = CrossValidator(estimator=xgb,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3,\n",
    "                          parallelism=2)\n",
    "\n",
    "cvModel = crossval.fit(train_data)\n",
    "bestModel_xgb = cvModel.bestModel\n",
    "\n",
    "pred_xgb = bestModel_xgb.transform(valid_data)\n",
    "\n",
    "xgb_rmse, xgb_r2 = evaluate(pred_xgb, label_col)\n",
    "\n",
    "param_map = bestModel_xgb.extractParamMap()\n",
    "\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(f\"  - max_depth: {bestModel_xgb.getOrDefault('max_depth')}\")\n",
    "print(f\"  - learning_rate: {bestModel_xgb.getOrDefault('learning_rate')}\")\n",
    "print(f\"  - subsample: {bestModel_xgb.getOrDefault('subsample')}\")\n",
    "print(f\"  - colsample_bytree: {bestModel_xgb.getOrDefault('colsample_bytree')}\")\n",
    "\n",
    "print(f\"\\nPerformance:\")\n",
    "print(f\"  RMSE: {xgb_rmse:.4f}\")\n",
    "print(f\"  R²: {xgb_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b71273",
   "metadata": {},
   "source": [
    "#### 4.5. Đánh giá mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed93177b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đánh giá tất cả mô hình trên TEST SET:\n",
      "==================================================\n",
      "\n",
      "1. Linear Regression:\n",
      "RMSE = 208877.4408 | R² = 0.7097\n",
      "\n",
      "2. Decision Tree :\n",
      "RMSE = 185647.3547 | R² = 0.7707\n",
      "\n",
      "3. Random Forest :\n",
      "RMSE = 177980.4616 | R² = 0.7892\n",
      "\n",
      "4. XGBoost:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/27 08:19:06 WARN DAGScheduler: Broadcasting large task binary with size 1023.1 KiB\n",
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n",
      "25/10/27 08:19:08 WARN DAGScheduler: Broadcasting large task binary with size 1023.1 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 97728.1342 | R² = 0.9365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:XGBoost-PySpark:Do the inference on the CPUs\n"
     ]
    }
   ],
   "source": [
    "# Đánh giá tất cả mô hình trên test\n",
    "print(\"Đánh giá tất cả mô hình trên TEST SET:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. Linear Regression \n",
    "print(\"\\n1. Linear Regression:\")\n",
    "pred_lr = bestModel_lr.transform(test_data)\n",
    "lr_rmse, lr_r2 = evaluate(pred_lr, label_col)\n",
    "\n",
    "# 2. Decision Tree\n",
    "print(\"\\n2. Decision Tree :\")\n",
    "pred_dt_test = bestModel_dt.transform(test_data)\n",
    "dt_rmse, dt_r2 = evaluate(pred_dt_test, label_col)\n",
    "\n",
    "# 3. Random Forest \n",
    "print(\"\\n3. Random Forest :\")\n",
    "pred_rf_test = bestModel_rf.transform(test_data)\n",
    "rf_rmse, rf_r2 = evaluate(pred_rf_test, label_col)\n",
    "\n",
    "# 4. XGBoost \n",
    "print(\"\\n4. XGBoost:\")\n",
    "pred_xgb = bestModel_xgb.transform(test_data)\n",
    "xgb_rmse, xgb_r2 = evaluate(pred_xgb, label_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e980177",
   "metadata": {},
   "source": [
    "#### Tóm tắt kết quả các mô hình\n",
    "\n",
    "Dưới đây là kết quả so sánh hiệu suất của 4 mô hình dự đoán giá nhà:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "835c2f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BẢNG TỔNG KẾT KẾT QUẢ CÁC MÔ HÌNH\n",
      "============================================================\n",
      "          Mô hình          RMSE       R²\n",
      "Linear Regression 208877.440828 0.709720\n",
      "    Decision Tree 185647.354670 0.770696\n",
      "    Random Forest 177980.461619 0.789244\n",
      "          XGBoost  97728.134198 0.936456\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Tạo bảng tóm tắt kết quả từ các biến đã tính toán\n",
    "results_data = {\n",
    "    'Mô hình': ['Linear Regression', 'Decision Tree', 'Random Forest', 'XGBoost'],\n",
    "    'RMSE': [lr_rmse, dt_rmse, rf_rmse, xgb_rmse],\n",
    "    'R²': [lr_r2, dt_r2, rf_r2, xgb_r2]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "print(\"BẢNG TỔNG KẾT KẾT QUẢ CÁC MÔ HÌNH\")\n",
    "print(\"=\"*60)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
